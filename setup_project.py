"""School Data Processing Project Setup Script.

Provides an interactive, menu-driven interface for managing the school data processing pipeline.
Supports internationalized UI (English/Swedish), Python virtual environment management, dependency installation,
program description viewing, step-by-step pipeline execution, and log file inspection.

Features:
    1. Select UI language (English/Swedish).
    2. Manage Python virtual environment and install dependencies (can be skipped with --no-venv).
    3. Display descriptions of the project's programs.
    4. Run the data processing and website generation pipeline step-by-step.
    5. View log files generated by the programs.

Command-line options:
    --lang      Set UI language (en or sv).
    --no-venv   Skip virtual environment creation and dependency installation.

All internal comments are in English. UI text is internationalized.

When run interactively, presents a menu to create a virtual environment or continue without one.
Both choices are valid and supported. The --no-venv CLI flag works for automation, bypassing the menu.
"""

import argparse
import logging
import os
import re
import shutil
import subprocess
import sys
import venv
from collections.abc import Callable, Iterator
from collections.abc import Callable as _CallableType
from contextlib import contextmanager
from pathlib import Path
from typing import IO, Any

from src.config import (
    LANG as DEFAULT_LANG,
)
from src.config import (
    LOG_DIR,
    PROJECT_ROOT,
    REQUIREMENTS_FILE,
    REQUIREMENTS_LOCK_FILE,
    SRC_DIR,
    VENV_DIR,
)

# --- Rich / Questionary UI ---
try:  # Prefer rich for nicer CLI output and components
    from rich import print as rprint
    from rich.console import Console, Group
    from rich.layout import Layout
    from rich.live import Live
    from rich.markdown import Markdown
    from rich.panel import Panel
    from rich.rule import Rule
    from rich.syntax import Syntax
    from rich.table import Table

    _RICH_CONSOLE: Console | None = Console()
except Exception:  # pragma: no cover - fallback

    def rprint(
        *objects: Any,
        sep: str = " ",
        end: str = "\n",
        file: IO[str] | None = None,
        flush: bool = False,
    ) -> None:
        """Fallback replacement that mirrors builtins.print signature."""
        print(*objects, sep=sep, end=end, file=file, flush=flush)

    _RICH_CONSOLE = None


try:
    import questionary as _questionary

    questionary: Any | None = _questionary
    _HAS_Q = True
except Exception:  # pragma: no cover - fallback
    questionary = None
    _HAS_Q = False


def ui_has_rich() -> bool:
    """Return True if rich Console is available for enhanced UI."""
    return _RICH_CONSOLE is not None


# --- TUI prompt integration state (used to render prompts into the right panel) ---
_TUI_MODE: bool = False
_TUI_UPDATER: Callable[[Any], None] | None = None  # updates main (output) area
_TUI_PROMPT_UPDATER: Callable[[Any], None] | None = None  # updates prompt area
# Compose right-pane content: pipeline status table + optional progress panel
_STATUS_RENDERABLE: Any | None = None
_PROGRESS_RENDERABLE: Any | None = None


def _compose_and_update() -> None:
    """Compose status and progress renderables and push to right pane.

    When running under the dashboard TUI, this stacks the pipeline status table
    (if available) with an optional progress panel for program 2.
    """
    if not _TUI_MODE or _TUI_UPDATER is None:
        return
    content: Any
    if _STATUS_RENDERABLE is not None and _PROGRESS_RENDERABLE is not None:
        content = Group(_STATUS_RENDERABLE, _PROGRESS_RENDERABLE)
    elif _STATUS_RENDERABLE is not None:
        content = _STATUS_RENDERABLE
    elif _PROGRESS_RENDERABLE is not None:
        content = _PROGRESS_RENDERABLE
    else:
        content = Panel("", title="")
    _TUI_UPDATER(content)


def set_tui_mode(
    update_right: _CallableType[[Any], None] | None,
    update_prompt: _CallableType[[Any], None] | None = None,
) -> _CallableType[[], None]:
    """Enable in-app TUI updates and return a restore callback.

    Parameters
    ----------
    update_right : Callable[[Any], None] | None
        Function that updates the right/output area. When ``None``, disables TUI mode.
    update_prompt : Callable[[Any], None] | None, optional
        Function that updates the prompt area.

    Returns
    -------
    Callable[[], None]
        A function that, when called, restores the previous TUI adapter state.
    """
    global _TUI_MODE, _TUI_UPDATER, _TUI_PROMPT_UPDATER
    prev_mode, prev_upd, prev_pupd = _TUI_MODE, _TUI_UPDATER, _TUI_PROMPT_UPDATER
    if update_right is None:
        _TUI_MODE = False
        _TUI_UPDATER = None
        _TUI_PROMPT_UPDATER = None
    else:
        _TUI_MODE = True
        _TUI_UPDATER = update_right
        _TUI_PROMPT_UPDATER = update_prompt

    def _restore() -> None:
        global _TUI_MODE, _TUI_UPDATER, _TUI_PROMPT_UPDATER
        _TUI_MODE, _TUI_UPDATER, _TUI_PROMPT_UPDATER = prev_mode, prev_upd, prev_pupd

    return _restore


def ui_rule(title: str) -> None:
    """Render a visual rule/header to separate sections.

    Parameters
    ----------
    title : str
        Title to display centered in the rule.
    """
    if _RICH_CONSOLE:
        _RICH_CONSOLE.print(Rule(title, style="bold blue"))
    else:
        rprint("\n" + title)


def ui_header(title: str) -> None:
    """Render a prominent header panel when rich is available.

    Parameters
    ----------
    title : str
        Title text to display inside a panel.
    """
    if _RICH_CONSOLE:
        _RICH_CONSOLE.print(
            Panel.fit(title, style="bold white on blue", border_style="blue")
        )
    else:
        rprint(title)


@contextmanager
def ui_status(message: str) -> Iterator[None]:
    """Visual status spinner for longer actions (rich) or plain print fallback."""
    if _RICH_CONSOLE:
        with _RICH_CONSOLE.status(message, spinner="dots"):
            yield
    else:
        rprint(message)
        yield


def ui_info(message: str) -> None:
    """Print an informational message with subtle styling when available."""
    if ui_has_rich():
        rprint(f"[cyan]{message}[/cyan]")
    else:
        rprint(message)


def ui_success(message: str) -> None:
    """Print a success message with a checkmark when available."""
    if ui_has_rich():
        rprint(f"[green]✓ {message}[/green]")
    else:
        rprint(message)


def ui_warning(message: str) -> None:
    """Print a warning message with a warning sign when available."""
    if ui_has_rich():
        rprint(f"[yellow]⚠ {message}[/yellow]")
    else:
        rprint(message)


def ui_error(message: str) -> None:
    """Print an error message with a cross when available."""
    if ui_has_rich():
        rprint(f"[bold red]✗ {message}[/bold red]")
    else:
        rprint(message)


def ui_menu(items: list[tuple[str, str]]) -> None:
    """Render a simple two-column menu of (key, label) pairs using Rich if available.

    Parameters
    ----------
    items : list[tuple[str, str]]
        A list of (choice_key, display_label) tuples.
    """
    if _RICH_CONSOLE:
        table = Table(show_header=True, header_style="bold blue")
        table.add_column("#", style="bold")
        table.add_column("Val")
        for key, label in items:
            table.add_row(key, label)
        _RICH_CONSOLE.print(table)
    else:
        for key, label in items:
            rprint(f"{key}. {label}")


def ask_text(prompt: str, default: str | None = None) -> str:
    """Prompt user for free-form text using Questionary if available.

    Parameters
    ----------
    prompt : str
        The question to show.
    default : str | None
        Default value to use if input is empty.

    Returns
    -------
    str
        The entered text (or default when empty).

    Examples
    --------
    >>> # Example (interactive):  # doctest: +SKIP
    >>> # ask_text('Your name: ', default='Alice')  # doctest: +SKIP
    'Alice'
    """
    # TUI-mode: render prompt within the right content panel and read stdin
    if _TUI_MODE and _TUI_UPDATER is not None:
        if _TUI_PROMPT_UPDATER is not None:
            _TUI_PROMPT_UPDATER(Panel(f"{prompt}\n\n> ", title="Input"))
        try:
            import getpass

            value = getpass.getpass("")
        except Exception:
            value = input("")
        return value or (default or "")
    if _HAS_Q and questionary is not None:
        ans = questionary.text(prompt, default=default or "").ask()
        return (ans or (default or "")).strip()
    return input(prompt).strip() or (default or "")


def ask_confirm(prompt: str, default_yes: bool = True) -> bool:
    """Prompt user for a yes/no confirmation.

    Parameters
    ----------
    prompt : str
        The question to show.
    default_yes : bool
        Default answer if user presses Enter.

    Returns
    -------
    bool
        ``True`` for yes, ``False`` for no.

    Examples
    --------
    >>> # Example (interactive):  # doctest: +SKIP
    >>> # ask_confirm('Continue?', default_yes=True)  # doctest: +SKIP
    True
    """
    # TUI-mode: render prompt within the right content panel and read stdin
    if _TUI_MODE and _TUI_UPDATER is not None:
        suffix = "(Y/n)" if default_yes else "(y/N)"
        if _TUI_PROMPT_UPDATER is not None:
            _TUI_PROMPT_UPDATER(Panel(f"{prompt}  {suffix}\n\n> ", title="Confirm"))
        try:
            import getpass

            val = getpass.getpass("").strip().lower()
        except Exception:
            val = input("").strip().lower()
        if not val:
            return default_yes
        return val in ("y", "j", "yes")
    if _HAS_Q and questionary is not None:
        return bool(questionary.confirm(prompt, default=default_yes).ask())
    val = input(prompt).strip().lower()
    if not val:
        return default_yes
    return val in ("y", "j", "yes")


def ask_select(prompt: str, choices: list[str]) -> str:
    """Prompt user to select from a list of choices.

    Parameters
    ----------
    prompt : str
        The question/instruction to show.
    choices : list[str]
        Choices to present to the user.

    Returns
    -------
    str
        The selected value (or raw input when fallback is used).

    Examples
    --------
    >>> # Example (interactive):  # doctest: +SKIP
    >>> # ask_select('Pick one', ['A', 'B', 'C'])  # doctest: +SKIP
    'B'
    """
    if _HAS_Q and questionary is not None:
        return str(questionary.select(prompt, choices=choices).ask())
    rprint(prompt)
    for idx, ch in enumerate(choices, start=1):
        rprint(f"{idx}. {ch}")
    sel = input("> ").strip()
    try:
        i = int(sel) - 1
        return choices[i]
    except Exception:  # pragma: no cover - fallback path
        return sel  # pragma: no cover


def _build_dashboard_layout(content: Any) -> Any:
    """Create a Rich layout with header, menu (left), content (right), and footer.

    Parameters
    ----------
    content : Any
        Rich renderable to display in the content (right) area.

    Returns
    -------
    Layout
        A configured Rich Layout instance ready to print.

    Examples
    --------
    >>> # Smoke-test layout creation (non-visual):  # doctest: +SKIP
    >>> _ = _build_dashboard_layout(Panel("Welcome"))  # doctest: +SKIP
    """
    layout = Layout(name="root")
    layout.split(
        Layout(name="header", size=3),
        Layout(name="body"),
        Layout(name="footer", size=3),
    )
    layout["body"].split_row(Layout(name="menu", size=40), Layout(name="content"))
    # Split right content into prompt (small) and main (large)
    layout["content"].split(Layout(name="prompt", size=5), Layout(name="main"))

    # Header
    header_title = "Skoltexter by AI — Setup"
    layout["header"].update(
        Panel(header_title, border_style="blue", style="bold white on blue")
    )

    # Menu
    items = [
        ("1", translate("menu_option_1")),
        ("2", translate("menu_option_2")),
        ("3", translate("menu_option_3")),
        ("4", translate("menu_option_4")),
        ("5", translate("menu_option_5")),
        ("Q", translate("menu_option_q")),
        ("QQ", translate("menu_option_qq")),
        ("6", translate("menu_option_6")),
    ]
    menu_table = Table(show_header=True, header_style="bold blue")
    menu_table.add_column("#", style="bold")
    menu_table.add_column("Action")
    for k, label in items:
        # Remove the numeric prefix like "1. " from translated labels if present
        display = label
        if label and label[0:3].isdigit():  # pragma: no cover - defensive
            try:
                display = label.split(" ", 1)[1]
            except Exception:  # pragma: no cover - defensive
                display = label
        elif label.startswith("1.") or label.startswith("2."):
            display = label[3:]
        menu_table.add_row(k, display)
    layout["menu"].update(Panel(menu_table, title="Meny", border_style="blue"))

    # Content
    layout["main"].update(content)

    # Footer
    venv_status = str(VENV_DIR.resolve()) if VENV_DIR.exists() else "<not created>"
    lang_label = "Svenska" if LANG == "sv" else "English"
    footer_text = f"Language: {lang_label} | Venv: {venv_status}"
    layout["footer"].update(Panel(footer_text, border_style="blue"))
    return layout


# --- Platform-specific virtual environment path helpers ---
def get_venv_bin_dir(venv_path: Path) -> Path:
    """Return the bin/Scripts directory for a virtual environment.

    Parameters
    ----------
    venv_path : Path
        Path to the virtual environment directory.

    Returns
    -------
    Path
        The ``bin`` directory on Unix/Linux/macOS or ``Scripts`` directory on Windows.
    """
    if sys.platform == "win32":
        return venv_path / "Scripts"
    else:
        return venv_path / "bin"


def get_venv_python_executable(venv_path: Path) -> Path:
    """Return the Python executable path for a virtual environment.

    Parameters
    ----------
    venv_path : Path
        Path to the virtual environment directory.

    Returns
    -------
    Path
        Path to the Python executable (``python.exe`` on Windows, ``python`` on Unix-like systems).
    """
    bin_dir = get_venv_bin_dir(venv_path)
    if sys.platform == "win32":
        return bin_dir / "python.exe"
    else:
        return bin_dir / "python"


def get_venv_pip_executable(venv_path: Path) -> Path:
    """Return the pip executable path for a virtual environment.

    Parameters
    ----------
    venv_path : Path
        Path to the virtual environment directory.

    Returns
    -------
    Path
        Path to the ``pip`` executable (``pip.exe`` on Windows, ``pip`` on Unix-like systems).
    """
    bin_dir = get_venv_bin_dir(venv_path)
    if sys.platform == "win32":
        return bin_dir / "pip.exe"
    else:
        return bin_dir / "pip"


# --- Logging Setup ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(module)s - %(funcName)s - %(message)s",
)
logger = logging.getLogger(__name__)

# --- Azure OpenAI .env Setup Constants ---
ENV_PATH = Path(".env")
ENV_EXAMPLE_PATH = Path(".env-example")
REQUIRED_AZURE_KEYS = [
    "AZURE_API_KEY",
    "AZURE_ENDPOINT_BASE",
    "GPT4O_DEPLOYMENT_NAME",
    "AZURE_API_VERSION",
]
ENV_KEY_VALUE_PATTERN = re.compile(r'^\s*([A-Z0-9_]+)\s*=\s*["\']?(.*?)["\']?\s*$')

# --- Internationalization (i18n) ---
TEXTS: dict[str, dict[str, str]] = {
    "en": {
        "welcome": "Welcome to the School Data Processing Project Setup!",
        "language_prompt": "Select language (1 for English, 2 for Svenska): ",
        "invalid_choice": "Invalid choice. Please try again.",
        "venv_active": "A virtual environment is already active: ",
        "venv_exists": f"Virtual environment '{VENV_DIR.name}' already exists.",
        "venv_menu_title": "\n--- Virtual Environment Setup ---",
        "venv_menu_option_1": "1. Create a virtual environment and install dependencies",
        "venv_menu_option_2": "2. Continue without a virtual environment",
        "venv_menu_prompt": "Choose an option (1 or 2): ",
        "venv_menu_info": "",
        "create_venv_prompt": "Create/recreate and install dependencies? (y/n, default y): ",
        "activate_venv_prompt": f"Virtual environment '{VENV_DIR.name}' exists. Install/update dependencies? (y/n, default y): ",
        "no_venv_prompt": f"No virtual environment found. Create '{VENV_DIR.name}' and install dependencies? (y/n, default y): ",
        "creating_venv": "Creating virtual environment...",
        "installing_deps": "Installing dependencies...",
        "deps_installed": "Dependencies installed.",
        "deps_install_failed": "Failed to install dependencies.",
        "venv_ready": "Virtual environment is set up.",
        "venv_skipped": "Virtual environment setup skipped.",
        "main_menu_title": "\n--- Main Menu ---",
        "menu_option_1": "1. Manage Virtual Environment & Dependencies",
        "menu_option_2": "2. View Program Descriptions",
        "menu_option_3": "3. Run Processing Pipeline",
        "menu_option_4": "4. View Logs",
        "menu_option_5": "5. Reset Project",
        "menu_option_6": "6. Exit",
        "menu_option_q": "Run Full Local Quality Suite",
        "menu_option_qq": "Run EXTREME Quality Suite (100x pytest + mutmut)",
        "enter_choice": "Enter your choice: ",
        "program_descriptions_title": "\n--- Program Descriptions ---",
        "program_1_desc_short": "Program 1 (Generate Markdowns from CSV)",
        "program_1_desc_long": (
            "Reads school data from the main CSV file and uses a template "
            "to generate individual markdown files for each school."
        ),
        "program_2_desc_short": "Program 2 (AI Processor for School Descriptions)",
        "program_2_desc_long": (
            "Takes the markdown files from Program 1 and sends their content to an "
            "AI service. The AI generates more detailed school descriptions."
        ),
        "program_3_desc_short": "Program 3 (Generate Website)",
        "program_3_desc_long": (
            "Loads school names from the CSV and their AI-generated descriptions "
            "and generates a standalone HTML file."
        ),
        "select_program_to_describe": "Select program to describe (1, 2, 3, or 0 to return): ",
        "pipeline_title": "\n--- Run Processing Pipeline ---",
        "pipeline_skip_info": "",
        "run_program_1_prompt": "Run Program 1? (y/n/s, default y): ",
        "running_program_1": "Running Program 1...",
        "program_1_complete": "Program 1 completed.",
        "program_1_failed": "Program 1 failed or was skipped.",
        "run_program_2_prompt": "Run Program 2? (y/n/s, default y): ",
        "running_program_2": "Running Program 2...",
        "program_2_complete": "Program 2 completed.",
        "program_2_failed": "Program 2 failed or was skipped.",
        "program_2_skipped": "Program 2 skipped.",
        "run_program_3_prompt": "Run Program 3? (y/n/s, default y): ",
        "running_program_3": "Running Program 3...",
        "program_3_complete": "Program 3 completed.",
        "program_3_failed": "Program 3 failed or was skipped.",
        "pipeline_complete": "Processing pipeline finished.",
        "ai_check_title": "\n--- AI Connectivity Check ---",
        "ai_check_prompt": "Run a quick AI connectivity test? (y/n, default y): ",
        "ai_check_running": "Testing AI connectivity...",
        "ai_check_ok": "AI connectivity OK. Received expected reply.",
        "ai_check_fail": "AI connectivity failed. Please verify your .env, network, and Azure settings.",
        "logs_title": "\n--- View Logs ---",
        "no_logs": f"No log files found in {LOG_DIR}",
        "select_log_prompt": "Enter the log file name to view (or 0 to return): ",
        "viewing_log": "Viewing log: ",
        "log_not_found": "Log file not found.",
        "exiting": "Exiting setup script.",
        "confirm_recreate_venv": f"WARNING: '{VENV_DIR.name}' exists. Recreate? (y/n, default n): ",
        "return_to_menu": "Return to Main Menu",
        "reset_option": "6. Reset Project",
        "reset_confirm": "Delete ALL generated files? (y/n, default n): ",
        "reset_complete": "Project reset completed.",
        "reset_cancelled": "Reset cancelled.",
        "azure_env_intro": "The following Azure OpenAI values are required for local storage so the program can call Azure OpenAI.",
        "azure_env_storage": "They will be stored in the .env file. These values are only needed for local storage and are not shared.",
        "azure_env_prompt": "Enter value for {key}: ",
        "quality_suite_ok": "All local quality checks passed.",
        "quality_suite_fail": "One or more local quality checks failed.",
    },
    "sv": {
        "welcome": "Välkommen till installationsprogrammet för skoldata!",
        "language_prompt": "Välj språk (1 för Engelska, 2 för Svenska): ",
        "invalid_choice": "Ogiltigt val. Försök igen.",
        "venv_active": "En virtuell miljö är redan aktiv: ",
        "venv_exists": f"Virtuell miljö '{VENV_DIR.name}' finns redan.",
        "venv_menu_title": "\n--- Virtuell Miljö ---",
        "venv_menu_option_1": "1. Skapa virtuell miljö och installera beroenden",
        "venv_menu_option_2": "2. Fortsätt utan virtuell miljö",
        "venv_menu_prompt": "Välj ett alternativ (1 eller 2): ",
        "venv_menu_info": "",
        "create_venv_prompt": "Skapa/återskapa och installera beroenden? (y/n, standard y): ",
        "activate_venv_prompt": f"Virtuell miljö '{VENV_DIR.name}' finns. Installera/uppdatera beroenden? (y/n, standard y): ",
        "no_venv_prompt": f"Ingen virtuell miljö hittades. Skapa '{VENV_DIR.name}' och installera beroenden? (y/n, standard y): ",
        "creating_venv": "Skapar virtuell miljö...",
        "installing_deps": "Installerar beroenden...",
        "deps_installed": "Beroenden installerade.",
        "deps_install_failed": "Misslyckades installera beroenden.",
        "venv_ready": "Virtuell miljö är klar.",
        "venv_skipped": "Virtuell miljö hoppades över.",
        "main_menu_title": "\n--- Huvudmeny ---",
        "menu_option_1": "1. Hantera virtuell miljö & beroenden",
        "menu_option_2": "2. Visa programbeskrivningar",
        "menu_option_3": "3. Kör bearbetningsflöde",
        "menu_option_4": "4. Visa loggar",
        "menu_option_5": "5. Återställ projekt",
        "menu_option_6": "6. Avsluta",
        "menu_option_q": "Kör full lokal kvalitetssvit",
        "menu_option_qq": "Kör EXTREM kvalitetssvit (100x pytest + mutmut)",
        "enter_choice": "Ange ditt val: ",
        "program_descriptions_title": "\n--- Programbeskrivningar ---",
        "program_1_desc_short": "Program 1 (Generera markdown från CSV)",
        "program_1_desc_long": (
            "Läser skoldata från huvud-CSV och använder en mall "
            "för att skapa individuella markdown-filer för varje skola."
        ),
        "program_2_desc_short": "Program 2 (AI-processor för skolbeskrivningar)",
        "program_2_desc_long": (
            "Tar markdown-filer från Program 1 och skickar innehållet till en "
            "AI-tjänst. AI genererar mer detaljerade skolbeskrivningar."
        ),
        "program_3_desc_short": "Program 3 (Generera webbplats)",
        "program_3_desc_long": (
            "Laddar skolnamn från CSV och deras AI-genererade beskrivningar "
            "och skapar en fristående HTML-fil."
        ),
        "select_program_to_describe": "Välj program att beskriva (1, 2, 3, eller 0 för att återgå): ",
        "pipeline_title": "\n--- Kör bearbetningsflöde ---",
        "pipeline_skip_info": "",
        "run_program_1_prompt": "Kör Program 1? (y/n/s, standard y): ",
        "running_program_1": "Kör Program 1...",
        "program_1_complete": "Program 1 klar.",
        "program_1_failed": "Program 1 misslyckades eller hoppade över.",
        "run_program_2_prompt": "Kör Program 2? (y/n/s, standard y): ",
        "running_program_2": "Kör Program 2...",
        "program_2_complete": "Program 2 klar.",
        "program_2_failed": "Program 2 misslyckades eller hoppade över.",
        "program_2_skipped": "Program 2 hoppade över.",
        "run_program_3_prompt": "Kör Program 3? (y/n/s, standard y): ",
        "running_program_3": "Kör Program 3...",
        "program_3_complete": "Program 3 klar.",
        "program_3_failed": "Program 3 misslyckades eller hoppade över.",
        "pipeline_complete": "Bearbetningsflöde klart.",
        "ai_check_title": "\n--- AI-anslutningstest ---",
        "ai_check_prompt": "Kör ett snabbt AI-anslutningstest? (y/n, standard y): ",
        "ai_check_running": "Testar AI-anslutning...",
        "ai_check_ok": "AI-anslutning OK. Fick förväntat svar.",
        "ai_check_fail": "AI-anslutning misslyckades. Kontrollera .env, nätverk och Azure-inställningar.",
        "logs_title": "\n--- Visa loggar ---",
        "no_logs": f"Inga loggfiler hittades i {LOG_DIR}",
        "select_log_prompt": "Ange loggfilens namn att visa (eller 0 för att återgå): ",
        "viewing_log": "Visar logg: ",
        "log_not_found": "Loggfil hittades inte.",
        "exiting": "Avslutar installationsprogrammet.",
        "confirm_recreate_venv": f"VARNING: '{VENV_DIR.name}' finns. Återskapa? (y/n, standard n): ",
        "return_to_menu": "Återgå till huvudmenyn",
        "reset_option": "6. Återställ projekt",
        "reset_confirm": "Radera ALLA genererade filer? (y/n, standard n): ",
        "reset_complete": "Projektet återställt.",
        "reset_cancelled": "Återställning avbröts.",
        "azure_env_intro": "Följande Azure OpenAI-värden krävs för lokal lagring så att programmet kan använda Azure OpenAI.",
        "azure_env_storage": "De sparas i .env-filen. Dessa värden behövs endast för lokal lagring och delas inte.",
        "azure_env_prompt": "Ange värde för {key}: ",
        "quality_suite_ok": "Alla lokala kvalitetskontroller passerade.",
        "quality_suite_fail": "En eller flera lokala kvalitetskontroller misslyckades.",
    },
}
LANG = DEFAULT_LANG


def translate(text_key: str) -> str:
    """Return a localized string for the current UI language.

    Parameters
    ----------
    text_key : str
        Lookup key for the localized text.

    Returns
    -------
    str
        Localized string for the current language, or the English fallback when missing.

    Examples
    --------
    >>> isinstance(translate('welcome'), str)
    True
    """
    if LANG not in TEXTS:
        logger.warning(
            f"Unsupported language '{LANG}' selected. Falling back to English."
        )
        return TEXTS["en"].get(text_key, text_key)
    return TEXTS[LANG].get(text_key, TEXTS["en"].get(text_key, text_key))


LANG = DEFAULT_LANG


def _(text_key: str) -> str:
    """Alias of :func:`translate` returning a localized string.

    Parameters
    ----------
    text_key : str
        Lookup key for the localized text.

    Returns
    -------
    str
        Localized string for the current language, or the English fallback when missing.

    Examples
    --------
    >>> isinstance(_('welcome'), str)
    True
    """
    if LANG not in TEXTS:
        logger.warning(
            f"Unsupported language '{LANG}' selected. Falling back to English."
        )
        return TEXTS["en"].get(text_key, text_key)
    return TEXTS[LANG].get(text_key, TEXTS["en"].get(text_key, text_key))


def set_language() -> None:
    """Prompt for UI language and update the global setting.

    Prompts the user to choose a language for the UI and updates the
    global ``LANG`` variable accordingly. Exits the program on keyboard
    interrupt.

    Returns
    -------
    None
    """
    global LANG
    while True:
        try:
            choice = ask_text(TEXTS["en"]["language_prompt"])
            if choice == "1":
                LANG = "en"
                break
            if choice == "2":
                LANG = "sv"
                break
            rprint(TEXTS["en"]["invalid_choice"])
        except KeyboardInterrupt:
            rprint(TEXTS["en"]["exiting"])
            sys.exit(0)
        except Exception:
            rprint(TEXTS["en"]["invalid_choice"])
    if LANG not in TEXTS:
        LANG = "en"  # pragma: no cover - defensive fallback


def is_venv_active() -> bool:
    """Return whether a Python virtual environment is active.

    Returns
    -------
    bool
        ``True`` if a virtual environment is active; otherwise ``False``.
    """
    return (
        hasattr(sys, "prefix") and sys.prefix != sys.base_prefix
    )  # pragma: no cover - environment-specific


def get_python_executable() -> str:
    """Return the path to the Python executable for the current environment.

    Returns
    -------
    str
        Path to the Python executable in the active virtual environment,
        the project's venv if it exists, or the system Python otherwise.
    """
    if is_venv_active():
        return sys.executable
    venv_python = get_venv_python_executable(VENV_DIR)
    if venv_python.exists():
        return str(venv_python)
    return sys.executable  # pragma: no cover - system fallback


def manage_virtual_environment() -> None:
    """Create, activate, or recreate a virtual environment and install dependencies.

    Prompts the user to create, activate, or recreate a Python virtual
    environment. Installs dependencies from ``REQUIREMENTS_FILE``. Handles
    user input, logs errors, and prints status messages.

    Returns
    -------
    None
    """
    pip_executable: Path | None = None
    python_executable: Path | None = None
    if is_venv_active():  # pragma: no cover - dependent on external runner env
        pip_executable = get_venv_pip_executable(Path(sys.prefix))
        python_executable = get_venv_python_executable(Path(sys.prefix))
        prompt_text = _("activate_venv_prompt")
        default_choice = "y"
    elif VENV_DIR.exists():
        pip_executable = get_venv_pip_executable(VENV_DIR)
        python_executable = get_venv_python_executable(VENV_DIR)
        prompt_text = _("create_venv_prompt")
        default_choice = "y"
    else:
        prompt_text = _("no_venv_prompt")
        default_choice = "y"
    choice = ask_text(prompt_text, default=default_choice).lower()
    if choice not in ["y", "j"]:
        rprint(_("venv_skipped"))
        return
    if not is_venv_active() and VENV_DIR.exists():
        recreate_choice = ask_text(_("confirm_recreate_venv"), default="n").lower()
        if recreate_choice in ["y", "j"]:
            try:
                from src.setup.fs_utils import create_safe_path, safe_rmtree

                try:
                    validated = create_safe_path(VENV_DIR)
                    safe_rmtree(validated)
                except PermissionError as e:
                    logger.error(f"Security policy prevented removing venv: {e}")
                    return
            except Exception as error:
                logger.error(f"Error removing venv: {error}")
                return
        elif choice not in ["y", "j"]:  # pragma: no cover - no-op guard
            pass
        else:  # pragma: no cover - user-decline branch
            ui_info(_("venv_skipped"))
            return
    if not is_venv_active() and not VENV_DIR.exists():
        ui_info(_("creating_venv"))
        try:
            # Prefer creating venv with Python 3.13 when available to use the
            # latest stable runtime by default. During tests, fall back to
            # stdlib venv.create to keep tests deterministic.
            created = False
            if not os.environ.get("PYTEST_CURRENT_TEST"):
                try:
                    if sys.platform == "win32":
                        if shutil.which("py") is not None:
                            subprocess.check_call(
                                ["py", "-3.13", "-m", "venv", str(VENV_DIR)]
                            )
                            created = True
                    else:
                        py313 = shutil.which("python3.13")
                        if py313:
                            subprocess.check_call([py313, "-m", "venv", str(VENV_DIR)])
                            created = True
                except Exception:
                    created = False
            if not created:
                venv.create(VENV_DIR, with_pip=True)

            pip_executable = get_venv_pip_executable(VENV_DIR)
            python_executable = get_venv_python_executable(VENV_DIR)
        except Exception as error:
            logger.error(f"Error creating virtual environment: {error}")
            return
    if not pip_executable or not pip_executable.exists():
        if VENV_DIR.exists():
            pip_executable = get_venv_pip_executable(VENV_DIR)

    # Determine Python executable to use for pip commands
    pip_python: str | None = None
    if python_executable and python_executable.exists():
        pip_python = str(python_executable)
    elif is_venv_active():  # pragma: no cover - depends on active env
        pip_python = sys.executable
    elif VENV_DIR.exists():
        venv_python = get_venv_python_executable(VENV_DIR)
        if venv_python.exists():
            pip_python = str(venv_python)  # pragma: no cover - indirect path

    # Fallback to system Python if nothing else works
    if not pip_python:
        pip_python = sys.executable

    try:
        # Use a static message instead of a live spinner to avoid
        # visual artifacts when pip renders its own progress output.
        ui_info(_("installing_deps"))
        # Use python -m pip instead of direct pip to avoid Windows issues and
        # disable progress bar/version check to keep the output clean.
        subprocess.check_call(
            [
                pip_python,
                "-m",
                "pip",
                "install",
                "--upgrade",
                "pip",
                "--disable-pip-version-check",
            ]
        )
        # Prefer reproducible, hash-locked installation when requirements.lock exists.
        if REQUIREMENTS_LOCK_FILE.exists():
            subprocess.check_call(
                [
                    pip_python,
                    "-m",
                    "pip",
                    "install",
                    "--require-hashes",
                    "-r",
                    str(REQUIREMENTS_LOCK_FILE),
                    "--progress-bar",
                    "off",
                    "--no-input",
                    "--disable-pip-version-check",
                ]
            )
        else:
            subprocess.check_call(
                [
                    pip_python,
                    "-m",
                    "pip",
                    "install",
                    "-r",
                    str(REQUIREMENTS_FILE),
                    "--progress-bar",
                    "off",
                    "--no-input",
                    "--disable-pip-version-check",
                ]
            )
        rprint(
            f"[green]✓[/green] {_('deps_installed')}"
            if ui_has_rich()
            else _("deps_installed")
        )
        rprint(
            f"[green]✓[/green] {_('venv_ready')}" if ui_has_rich() else _("venv_ready")
        )
        # After a successful install, ensure we pick up the "nice" UI (rich/questionary).
        # If we're not currently inside the venv where dependencies were installed,
        # restart this script using the venv's Python so the nicer UI is available.
        try:
            venv_python = get_venv_python_executable(VENV_DIR)
            if (
                not is_venv_active()
                and venv_python.exists()
                and not os.environ.get("SETUP_SWITCHED_UI")
            ):
                # Mark that we're switching UI to avoid loops and skip language prompt on restart
                env = os.environ.copy()
                env["SETUP_SWITCHED_UI"] = "1"
                env["SETUP_SKIP_LANGUAGE_PROMPT"] = "1"
                # Build arguments for a smooth restart: keep language selection and skip venv flow
                argv = [
                    str(venv_python),
                    str(PROJECT_ROOT / "setup_project.py"),
                ]
                if LANG in ("en", "sv"):
                    argv.extend(["--lang", LANG])
                argv.append("--no-venv")
                rprint("\n[cyan]Restarting with enhanced UI...[/cyan]")
                # Replace current process to ensure fresh imports for rich/questionary
                os.execve(str(venv_python), argv, env)
            else:
                # If already in venv, try to enable rich/questionary dynamically
                try:
                    from rich import print as _rp

                    globals()["rprint"] = _rp  # swap to rich.print
                except Exception:
                    pass
                try:
                    import importlib

                    globals()["questionary"] = importlib.import_module("questionary")
                    globals()["_HAS_Q"] = True
                except Exception:
                    pass
        except Exception as _ui_err:  # pragma: no cover - best effort UI upgrade
            logger.debug(f"UI switch not applied: {_ui_err}")
    except subprocess.CalledProcessError as error:
        logger.error(f"{_('deps_install_failed')} Error: {error}")
    except FileNotFoundError:
        logger.error(f"Error: {pip_python} or {REQUIREMENTS_FILE} not found.")


def run_program(
    program_name: str, program_file: Path, stream_output: bool = False
) -> bool:
    """Run a specified program script as a subprocess with language and log level.

    Parameters
    ----------
    program_name : str
        The name of the program (for logging and i18n).
    program_file : Path
        The path to the program script.
    stream_output : bool, default False
        If ``True``, stream stdout/stderr to user in real time.

    Returns
    -------
    bool
        ``True`` if the program ran successfully, otherwise ``False``.

    Notes
    -----
    This function logs messages, prints output, and may stream subprocess output to the console.
    """
    python_executable = get_python_executable()
    logger.info(f"{_(program_name)} ({program_file.name})...")

    # Pass language and log level to subprocess
    lang_arg = f"--lang={LANG}"
    log_level_arg = "--log-level=INFO"
    module_name = (
        f"src.{program_file.stem}"
        if program_file.parent.name == "src"
        else program_file.with_suffix("").as_posix().replace("/", ".")
    )
    env = os.environ.copy()
    env["LANG_UI"] = LANG

    try:
        if stream_output:
            # Stream output in real time
            if _TUI_MODE and _TUI_UPDATER is not None and program_name == "program_2":
                # Capture output to drive a progress panel inside the right content
                proc = subprocess.Popen(
                    [python_executable, "-m", module_name, lang_arg, log_level_arg],
                    cwd=PROJECT_ROOT,
                    env=env,
                    text=True,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    bufsize=1,
                )
                total: int | None = None
                current: int = 0
                bar_width = 40
                # Heuristic patterns for tqdm/output lines
                pct_re = re.compile(r"(\d+)%\|")
                frac_re = re.compile(r"(\d+)/(\d+)")
                done_re = re.compile(r"AI Processing completed: (\d+)")

                def render_progress() -> None:
                    global _PROGRESS_RENDERABLE
                    percent = int((current / max(total or 1, 1)) * 100) if total else 0
                    filled = int(percent * bar_width / 100)
                    bar = "█" * filled + "░" * (bar_width - filled)
                    text = f"[{bar}] {percent:3d}%"
                    if total:
                        text += f"  {current}/{total}"
                    _PROGRESS_RENDERABLE = Panel(
                        text, title="AI Processor", border_style="cyan"
                    )
                    _compose_and_update()

                # Initial progress render
                render_progress()
                assert proc.stdout is not None
                for raw in proc.stdout:
                    line = raw.rstrip("\n\r")
                    m = done_re.search(line)
                    if m:
                        current = int(m.group(1))
                        if total is None:
                            total = current
                        render_progress()
                        continue
                    m = pct_re.search(line)
                    if m:
                        perc = int(m.group(1))
                        total = 100
                        current = perc
                        render_progress()
                        continue
                    m = frac_re.search(line)
                    if m:
                        cur = int(m.group(1))
                        tot = int(m.group(2))
                        total = tot
                        current = cur
                        render_progress()
                        continue
                return_code = proc.wait()
                # Clear progress panel after completion
                global _PROGRESS_RENDERABLE
                _PROGRESS_RENDERABLE = None
                _compose_and_update()
                if return_code == 0:
                    logger.info(_(f"{program_name.lower().replace(' ', '_')}_complete"))
                    return True
                fail_key_str = f"{program_name.lower().replace(' ', '_')}_failed"
                logger.error(f"{_(fail_key_str)} (Return code: {return_code})")
                return False

            # Default streaming path
            proc = subprocess.Popen(
                [python_executable, "-m", module_name, lang_arg, log_level_arg],
                cwd=PROJECT_ROOT,
                env=env,
                text=True,
                stdout=sys.stdout,
                stderr=sys.stderr,
            )
            return_code = proc.wait()
            if return_code == 0:
                logger.info(_(f"{program_name.lower().replace(' ', '_')}_complete"))
                return True
            fail_key_str = f"{program_name.lower().replace(' ', '_')}_failed"
            logger.error(f"{_(fail_key_str)} (Return code: {return_code})")
            return False
        else:
            result = subprocess.run(
                [python_executable, "-m", module_name, lang_arg, log_level_arg],
                cwd=PROJECT_ROOT,
                check=False,
                capture_output=True,
                text=True,
                env=env,
            )
            if result.returncode == 0:
                logger.info(_(f"{program_name.lower().replace(' ', '_')}_complete"))
                return True
            fail_key_str = f"{program_name.lower().replace(' ', '_')}_failed"
            logger.error(f"{_(fail_key_str)} (Return code: {result.returncode})")
            logger.error(
                "Subprocess output:\n" + (result.stdout or "") + (result.stderr or "")
            )
            return False
    except Exception as error:
        logger.error(f"Error running {program_file.name}: {error}")
        return False


def get_program_descriptions() -> dict[str, tuple[str, str]]:
    """Return program descriptions for the current language.

    Returns
    -------
    dict[str, tuple[str, str]]
        Mapping of program numbers (as strings) to ``(short_description, long_description)``.
    """
    return {
        "1": (translate("program_1_desc_short"), translate("program_1_desc_long")),
        "2": (translate("program_2_desc_short"), translate("program_2_desc_long")),
        "3": (translate("program_3_desc_short"), translate("program_3_desc_long")),
    }


def view_program_descriptions() -> None:
    """Display and interactively describe each program in the project.

    Prompts the user to select a program and displays both its short and long
    description. The user can return to the main menu.

    Returns
    -------
    None
    """
    ui_rule(translate("program_descriptions_title"))
    while True:
        descriptions = get_program_descriptions()
        items = [(k, v[0]) for k, v in descriptions.items()]
        items.append(("0", translate("return_to_menu")))
        ui_menu(items)
        choice = ask_text(translate("select_program_to_describe"))
        if choice == "0":
            break
        if choice in descriptions:
            ui_header(descriptions[choice][0])
            if ui_has_rich():
                rprint(Markdown(descriptions[choice][1]))
            else:
                rprint(descriptions[choice][1])
        else:
            rprint(translate("invalid_choice"))


def _view_program_descriptions_tui(
    update_right: Callable[[Any], None], update_prompt: Callable[[Any], None]
) -> None:
    """Render program descriptions selection entirely in the right pane.

    Parameters
    ----------
    update_right : Callable[[Any], None]
        Function to update the output area.
    update_prompt : Callable[[Any], None]
        Function to update the prompt area.

    Returns
    -------
    None
    """
    while True:
        descriptions = get_program_descriptions()
        items = [(k, v[0]) for k, v in descriptions.items()]
        items.append(("0", translate("return_to_menu")))
        t = Table(show_header=True, header_style="bold blue")
        t.add_column("#")
        t.add_column("Val")
        for k, label in items:
            t.add_row(k, label)
        update_right(t)
        choice = ask_text(translate("select_program_to_describe"))
        if choice == "0":
            break
        if choice in descriptions:
            update_right(
                Panel(Markdown(descriptions[choice][1]), title=descriptions[choice][0])
            )
        else:
            update_right(
                Panel(translate("invalid_choice"), title="Info", border_style="yellow")
            )


def _view_logs_tui(
    update_right: Callable[[Any], None], update_prompt: Callable[[Any], None]
) -> None:
    """Render log selection in the right pane (no global prints).

    Parameters
    ----------
    update_right : Callable[[Any], None]
        Function to update the output area.
    update_prompt : Callable[[Any], None]
        Function to update the prompt area.

    Returns
    -------
    None
    """
    if not LOG_DIR.exists() or not any(LOG_DIR.iterdir()):
        update_right(Panel(translate("no_logs"), title="Logs"))
        return
    log_files = sorted(
        [p for p in LOG_DIR.iterdir() if p.is_file() and p.name.endswith(".log")]
    )
    if not log_files:
        update_right(Panel(translate("no_logs"), title="Logs"))
        return
    while True:
        tbl = Table(show_header=True, header_style="bold blue")
        tbl.add_column("#")
        tbl.add_column("Log")
        for i, p in enumerate(log_files, 1):
            tbl.add_row(str(i), p.name)
        tbl.add_row("0", translate("return_to_menu"))
        update_right(Panel(tbl, title="Logs"))
        choice = ask_text(translate("select_log_prompt"))
        if choice == "0":
            break
        selected: Path | None = None
        if choice.isdigit():
            idx = int(choice) - 1
            if 0 <= idx < len(log_files):
                selected = log_files[idx]
        if not selected:
            selected = next(
                (p for p in log_files if p.name == choice or p.name.startswith(choice)),
                None,
            )
        if selected and selected.exists():
            txt = selected.read_text(encoding="utf-8")
            update_right(
                Panel(Syntax(txt, "text", theme="monokai"), title=selected.name)
            )
        else:
            update_right(
                Panel(translate("invalid_choice"), title="Info", border_style="yellow")
            )


def _run_processing_pipeline_plain() -> None:
    """Run the data processing programs sequentially with user confirmation.

    Executes each step in order, prompting for confirmation and providing
    localized feedback. Displays a message about opening the generated HTML file.

    Returns
    -------
    None
    """
    ui_rule(_("pipeline_title"))
    # Optional AI connectivity check before running the pipeline
    rprint(
        f"[bold]{translate('ai_check_title')}[/bold]"
        if ui_has_rich()
        else translate("ai_check_title")
    )
    if ask_confirm(translate("ai_check_prompt"), default_yes=True):
        ok = run_ai_connectivity_check_interactive()
        if not ok:
            return
    if not _run_pipeline_step(
        "run_program_1_prompt",
        "program_1",
        SRC_DIR / "program1_generate_markdowns.py",
        "program_1_failed",
        "markdown_created",
    ):
        return
    _run_pipeline_step(
        "run_program_2_prompt",
        "program_2",
        SRC_DIR / "program2_ai_processor.py",
        "program_2_failed",
        "ai_descriptions_created",
        skip_message="program_2_skipped",
        stream_output=True,
    )
    program3_success = _run_pipeline_step(
        "run_program_3_prompt",
        "program_3",
        SRC_DIR / "program3_generate_website.py",
        "program_3_failed",
        "website_created",
    )
    ui_success(_("pipeline_complete"))
    # After website generation, display localized message about opening the HTML file
    if program3_success:
        html_path = PROJECT_ROOT / "output" / "index.html"
        open_msg = {
            "en": f"\nOpen the file in your browser by double-clicking it in your file explorer:\n  {html_path.resolve()}",
            "sv": f"\nÖppna filen i din webbläsare genom att dubbelklicka på den i Utforskaren:\n  {html_path.resolve()}",
        }
        rprint(open_msg.get(LANG, open_msg["en"]))


def _status_label(base: str) -> str:
    """Return a localized status label with icon.

    Parameters
    ----------
    base : str
        Status keyword: one of "waiting", "running", "ok", "fail".

    Returns
    -------
    str
        Localized label decorated with an icon.
    """
    if LANG == "sv":
        labels = {
            "waiting": "⏳ Väntar",
            "running": "▶️ Körs",
            "ok": "✅ Klart",
            "fail": "❌ Misslyckades",
        }
    else:
        labels = {
            "waiting": "⏳ Waiting",
            "running": "▶️ Running",
            "ok": "✅ Done",
            "fail": "❌ Failed",
        }
    return labels.get(base, base)


def _render_pipeline_table(status1: str, status2: str, status3: str) -> Any:
    """Build a Rich table showing pipeline step statuses.

    Parameters
    ----------
    status1 : str
        Status for Program 1.
    status2 : str
        Status for Program 2.
    status3 : str
        Status for Program 3.

    Returns
    -------
    Table
        Rich table with three rows and status cells.
    """
    table = Table(
        title=translate("pipeline_title"), show_header=True, header_style="bold blue"
    )
    table.add_column("Step", style="bold")
    table.add_column("Status")
    table.add_row("Program 1", status1)
    table.add_row("Program 2", status2)
    table.add_row("Program 3", status3)
    return table


def _run_processing_pipeline_rich(
    content_updater: Callable[[Any], None] | None = None,
) -> None:
    """Run pipeline with a live Rich table and coarse progress for Program 2.

    The function preserves the existing confirmation prompts and uses a live
    status table to reflect step state changes. For Program 2, a spinner-style
    progress is shown while the step runs.

    Notes
    -----
    This function is intentionally longer than 40 lines to keep the orchestration
    of Rich Live layout and step transitions in one place. Splitting it across
    helpers would obscure the control flow of live updates and harm readability.

    Returns
    -------
    None
    """
    # Optional AI connectivity check before running
    # Enable TUI prompt mode for the duration of this rich pipeline run
    global _TUI_MODE, _TUI_UPDATER
    prev_mode, prev_updater = _TUI_MODE, _TUI_UPDATER
    if content_updater is not None:
        _TUI_MODE, _TUI_UPDATER = True, content_updater
        content_updater(Panel(translate("ai_check_title"), title="AI"))
    else:
        rprint(f"[bold]{translate('ai_check_title')}[/bold]")
    if ask_confirm(translate("ai_check_prompt"), default_yes=True):
        ok = run_ai_connectivity_check_interactive()
        if not ok:
            if content_updater is not None:
                content_updater(
                    Panel(translate("ai_check_fail"), title="AI", border_style="red")
                )
            # Restore TUI state
            _TUI_MODE, _TUI_UPDATER = prev_mode, prev_updater
            return

    s1 = _status_label("waiting")
    s2 = _status_label("waiting")
    s3 = _status_label("waiting")
    if content_updater is not None:
        # Update inside the right content panel instead of printing globally
        global _STATUS_RENDERABLE
        _STATUS_RENDERABLE = _render_pipeline_table(s1, s2, s3)
        _compose_and_update()
        # Program 1
        s1 = _status_label("running")
        _STATUS_RENDERABLE = _render_pipeline_table(s1, s2, s3)
        _compose_and_update()
        ok1 = _run_pipeline_step(
            "run_program_1_prompt",
            "program_1",
            SRC_DIR / "program1_generate_markdowns.py",
            "program_1_failed",
            "markdown_created",
        )
        s1 = _status_label("ok" if ok1 else "fail")
        _STATUS_RENDERABLE = _render_pipeline_table(s1, s2, s3)
        _compose_and_update()
        # Program 2
        s2 = _status_label("running")
        _STATUS_RENDERABLE = _render_pipeline_table(s1, s2, s3)
        _compose_and_update()
        ok2 = _run_pipeline_step(
            "run_program_2_prompt",
            "program_2",
            SRC_DIR / "program2_ai_processor.py",
            "program_2_failed",
            "ai_descriptions_created",
            skip_message="program_2_skipped",
            stream_output=True,
        )
        s2 = _status_label("ok" if ok2 else "fail")
        _STATUS_RENDERABLE = _render_pipeline_table(s1, s2, s3)
        _compose_and_update()
        # Program 3
        s3 = _status_label("running")
        _STATUS_RENDERABLE = _render_pipeline_table(s1, s2, s3)
        _compose_and_update()
        ok3 = _run_pipeline_step(
            "run_program_3_prompt",
            "program_3",
            SRC_DIR / "program3_generate_website.py",
            "program_3_failed",
            "website_created",
        )
        s3 = _status_label("ok" if ok3 else "fail")
        _STATUS_RENDERABLE = _render_pipeline_table(s1, s2, s3)
        _compose_and_update()
        ui_success(_("pipeline_complete"))
        if ok3:
            html_path = PROJECT_ROOT / "output" / "index.html"
            open_msg = {
                "en": f"\nOpen the file in your browser by double-clicking it in your file explorer:\n  {html_path.resolve()}",
                "sv": f"\nÖppna filen i din webbläsare genom att dubbelklicka på den i Utforskaren:\n  {html_path.resolve()}",
            }
            content_updater(Panel(open_msg.get(LANG, open_msg["en"]), title="Pipeline"))
        # Restore TUI state
        _TUI_MODE, _TUI_UPDATER = prev_mode, prev_updater
    else:
        # Fallback: live table printed globally
        with Live(
            _render_pipeline_table(s1, s2, s3),
            refresh_per_second=6,
            console=_RICH_CONSOLE,
        ) as live:
            # Program 1
            s1 = _status_label("running")
            live.update(_render_pipeline_table(s1, s2, s3))
            ok1 = _run_pipeline_step(
                "run_program_1_prompt",
                "program_1",
                SRC_DIR / "program1_generate_markdowns.py",
                "program_1_failed",
                "markdown_created",
            )
            s1 = _status_label("ok" if ok1 else "fail")
            # Program 2
            s2 = _status_label("running")
            live.update(_render_pipeline_table(s1, s2, s3))
            ok2 = _run_pipeline_step(
                "run_program_2_prompt",
                "program_2",
                SRC_DIR / "program2_ai_processor.py",
                "program_2_failed",
                "ai_descriptions_created",
                skip_message="program_2_skipped",
                stream_output=True,
            )
            s2 = _status_label("ok" if ok2 else "fail")
            live.update(_render_pipeline_table(s1, s2, s3))
            # Program 3
            s3 = _status_label("running")
            live.update(_render_pipeline_table(s1, s2, s3))
            ok3 = _run_pipeline_step(
                "run_program_3_prompt",
                "program_3",
                SRC_DIR / "program3_generate_website.py",
                "program_3_failed",
                "website_created",
            )
            s3 = _status_label("ok" if ok3 else "fail")
            live.update(_render_pipeline_table(s1, s2, s3))
        ui_success(_("pipeline_complete"))
        if ok3:
            html_path = PROJECT_ROOT / "output" / "index.html"
            open_msg = {
                "en": f"\nOpen the file in your browser by double-clicking it in your file explorer:\n  {html_path.resolve()}",
                "sv": f"\nÖppna filen i din webbläsare genom att dubbelklicka på den i Utforskaren:\n  {html_path.resolve()}",
            }
            rprint(open_msg.get(LANG, open_msg["en"]))


def run_processing_pipeline(
    content_updater: Callable[[Any], None] | None = None,
) -> None:
    """Run the processing pipeline with Rich dashboard when available.

    Chooses a Rich-enhanced execution when Rich is installed; otherwise falls
    back to the plain text implementation. Confirmation prompts and return
    behaviors are preserved for test compatibility.

    Returns
    -------
    None
    """
    if ui_has_rich():
        _run_processing_pipeline_rich(content_updater)
    else:
        _run_processing_pipeline_plain()


def _run_pipeline_step(
    prompt_key: str,
    program_name: str,
    program_path: Path,
    fail_key: str,
    confirmation_key: str,
    skip_message: str | None = None,
    stream_output: bool = False,
) -> bool:
    """Run a single pipeline step with user confirmation and feedback.

    Parameters
    ----------
    prompt_key : str
        Localization key for the user prompt.
    program_name : str
        Name of the program to run.
    program_path : Path
        Path to the program script.
    fail_key : str
        Localization key for the failure message.
    confirmation_key : str
        Localization key for the success/confirmation message.
    skip_message : str, optional
        Localization key for the skip message.
    stream_output : bool, default False
        If ``True``, stream output in real time.

    Returns
    -------
    bool
        ``True`` if the step succeeded, otherwise ``False``.
    """
    choice = ask_text(_(prompt_key), default="y").lower()
    if choice in ["y", "j"]:
        if not run_program(program_name, program_path, stream_output=stream_output):
            logger.error(_(fail_key) + " Aborting pipeline.")
            return False
        ui_success(_(confirmation_key))
    elif choice in ["s", "skip", "h", "hoppa"]:
        if skip_message:
            ui_info(_(skip_message))  # pragma: no cover - trivial print branch
        else:
            ui_warning(_(fail_key))  # pragma: no cover - trivial print branch
    else:
        ui_warning(_(fail_key))  # pragma: no cover - trivial print branch
        return False  # pragma: no cover
    return True


def view_logs() -> None:
    """List available log files and allow the user to view them.

    Prompts the user to select a log file to view, or to return to the previous menu.
    Handles file I/O and logs errors.

    Returns
    -------
    None
    """
    ui_rule(translate("logs_title"))
    if not LOG_DIR.exists() or not any(LOG_DIR.iterdir()):
        rprint(translate("no_logs"))
        return
    log_files = sorted(
        [
            file_path
            for file_path in LOG_DIR.iterdir()
            if file_path.is_file() and file_path.name.endswith(".log")
        ]
    )
    if not log_files:
        rprint(translate("no_logs"))
        return

    while True:
        ui_rule(translate("logs_title"))
        ui_menu(
            [(str(i), p.name) for i, p in enumerate(log_files, start=1)]
            + [("0", translate("return_to_menu"))]
        )
        try:
            choice = ask_text(translate("select_log_prompt"))
            if choice == "0":
                break
            # Allow selection by number or filename
            selected_log = None
            if choice.isdigit():
                log_index = int(choice) - 1
                if 0 <= log_index < len(log_files):
                    selected_log = log_files[log_index]
            if not selected_log:
                selected_log = next(
                    (
                        file_path
                        for file_path in log_files
                        if file_path.name == choice or file_path.name.startswith(choice)
                    ),
                    None,
                )
            if selected_log:
                rprint(f"\n--- {translate('viewing_log')}{selected_log.name} ---")
                with selected_log.open("r", encoding="utf-8") as file_handle:
                    content = file_handle.read()
                if ui_has_rich():
                    rprint(Syntax(content, "text", theme="monokai", line_numbers=False))
                else:
                    rprint(content)
                rprint(f"--- End of {selected_log.name} ---\n")
            else:
                rprint(translate("invalid_choice"))
        except Exception as error:  # pragma: no cover - OS-level I/O fault
            logger.error(f"Error reading log file: {error}")


def reset_project() -> None:
    """Delete all generated files and directories for a clean project reset.

    Prompts the user for confirmation before deleting generated files and directories.
    Handles file and directory deletion, prints status messages, and logs errors.

    Returns
    -------
    None
    """
    ui_rule(translate("menu_option_5").split(". ")[1])
    dirs_to_check = [
        PROJECT_ROOT / "data" / "generated_markdown_from_csv",
        PROJECT_ROOT / "data" / "ai_processed_markdown",
        PROJECT_ROOT / "data" / "ai_raw_responses",
        PROJECT_ROOT / "data" / "generated_descriptions",
        PROJECT_ROOT / "output",
        LOG_DIR,
    ]
    files_found = []
    for dir_path in dirs_to_check:
        if dir_path.exists():
            files_found.extend(
                [file_path for file_path in dir_path.rglob("*") if file_path.is_file()]
            )
    if not files_found:
        rprint("No generated files found to delete.")
        return
    rprint(f"Found {len(files_found)} generated files that will be deleted.")
    rprint("Directories that will be cleared:")
    for dir_path in dirs_to_check:
        if dir_path.exists() and any(dir_path.rglob("*")):
            rprint(f"  - {dir_path.relative_to(PROJECT_ROOT)}")
    confirm = ask_text(translate("reset_confirm"), default="n").lower()
    if confirm not in ["y", "j"]:
        rprint(
            translate("reset_cancelled")
        )  # pragma: no cover - simple user-decline path
        return  # pragma: no cover
    deleted_count = 0
    from src.setup.fs_utils import create_safe_path, safe_rmtree
    for dir_path in dirs_to_check:
        if dir_path.exists():
            # Attempt to validate and then safely rmtree the entire directory.
            try:
                validated = create_safe_path(dir_path)
                safe_rmtree(validated)
                # Count removed files as an approximation (directory cleared)
                deleted_count += 1
            except PermissionError as e:
                logger.error(f"Security policy prevented removing directory '{dir_path}': {e}")
            except Exception as error:
                logger.error(f"Error removing {dir_path}: {error}")
    rprint(f"{translate('reset_complete')} ({deleted_count} files deleted)")


def _main_menu_plain() -> None:
    """Display the plain text main menu and handle choices."""
    while True:
        ui_rule(translate("main_menu_title"))
        ui_menu(
            [
                (
                    "1",
                    (
                        translate("menu_option_1").split(" ", 1)[1]
                        if ": " not in translate("menu_option_1")
                        else translate("menu_option_1")[3:]
                    ),
                ),
                (
                    "2",
                    (
                        translate("menu_option_2").split(" ", 1)[1]
                        if ": " not in translate("menu_option_2")
                        else translate("menu_option_2")[3:]
                    ),
                ),
                (
                    "3",
                    (
                        translate("menu_option_3").split(" ", 1)[1]
                        if ": " not in translate("menu_option_3")
                        else translate("menu_option_3")[3:]
                    ),
                ),
                (
                    "4",
                    (
                        translate("menu_option_4").split(" ", 1)[1]
                        if ": " not in translate("menu_option_4")
                        else translate("menu_option_4")[3:]
                    ),
                ),
                (
                    "5",
                    (
                        translate("menu_option_5").split(" ", 1)[1]
                        if ": " not in translate("menu_option_5")
                        else translate("menu_option_5")[3:]
                    ),
                ),
                ("Q", translate("menu_option_q")),
                ("QQ", translate("menu_option_qq")),
                (
                    "6",
                    (
                        translate("menu_option_6").split(" ", 1)[1]
                        if ": " not in translate("menu_option_6")
                        else translate("menu_option_6")[3:]
                    ),
                ),
            ]
        )
        choice = ask_text(translate("enter_choice"))
        if choice == "1":  # pragma: no branch - coverage arc false-positive across loop
            manage_virtual_environment()
        elif choice == "2":
            view_program_descriptions()
        elif choice == "3":
            run_processing_pipeline()
        elif choice == "4":
            view_logs()
        elif choice == "5":
            reset_project()
        elif choice.lower() == "q":
            run_full_quality_suite()
        elif choice.lower() == "qq":
            run_extreme_quality_suite()
        elif choice == "6":
            rprint(translate("exiting"))
            break
        else:
            rprint(translate("invalid_choice"))


def _main_menu_rich_dashboard() -> None:
    """Render a lightweight Rich dashboard layout and route menu choices.

    The right content area shows a welcome text. Actions render their own
    views; for descriptions and logs, Rich renderables are used for better
    readability.

    Returns
    -------
    None
    """
    content = Panel(Markdown(translate("welcome")), title="Welcome")

    # Enable TUI prompts that render inside the right content panel for the
    # duration of the dashboard loop.
    global _TUI_MODE, _TUI_UPDATER
    prev_mode, prev_updater = _TUI_MODE, _TUI_UPDATER
    layout = _build_dashboard_layout(content)

    def update_right(renderable: Any) -> None:
        # Update main area without clearing the whole console
        layout["main"].update(renderable)
        if _RICH_CONSOLE is None:
            # Fallback printing when no console is available
            rprint(renderable)

    def update_prompt_area(renderable: Any) -> None:
        layout["prompt"].update(renderable)
        if _RICH_CONSOLE is None:
            rprint(renderable)

    _TUI_MODE, _TUI_UPDATER, _TUI_PROMPT_UPDATER = (
        True,
        update_right,
        update_prompt_area,
    )

    try:
        if _RICH_CONSOLE:
            from rich.live import Live as _Live

            with _Live(layout, refresh_per_second=10, console=_RICH_CONSOLE):
                while True:
                    choice = ask_text(translate("enter_choice"))
                    if choice == "1":
                        manage_virtual_environment()
                        update_right(
                            Panel(
                                "Environment managed.",
                                title="Status",
                                border_style="green",
                            )
                        )
                        continue
                    elif choice == "2":
                        view_program_descriptions()
                        update_right(Panel("Descriptions viewed.", title="Programs"))
                        continue
                    elif choice == "3":
                        # Update pipeline progress inside the right content panel
                        def set_content(renderable: Any) -> None:
                            update_right(renderable)

                        try:
                            run_processing_pipeline(content_updater=set_content)
                        except TypeError:
                            run_processing_pipeline()
                        update_right(
                            Panel(
                                _("pipeline_complete"),
                                title="Pipeline",
                                border_style="green",
                            )
                        )
                        continue
                    elif choice == "4":
                        view_logs()
                        update_right(Panel("Logs viewed.", title="Logs"))
                        continue
                    elif choice == "5":
                        reset_project()
                        update_right(
                            Panel(
                                _("reset_complete"), title="Reset", border_style="green"
                            )
                        )
                        continue
                    elif choice.lower() == "q":
                        run_full_quality_suite()
                        update_right(
                            Panel(
                                translate("quality_suite_ok"),
                                title="Quality",
                                border_style="green",
                            )
                        )
                        continue
                    elif choice.lower() == "qq":
                        run_extreme_quality_suite()
                        update_right(
                            Panel(
                                translate("quality_suite_ok"),
                                title="Quality",
                                border_style="green",
                            )
                        )
                        continue
                    elif choice == "6":
                        rprint(translate("exiting"))
                        break
                    else:
                        update_right(
                            Panel(
                                translate("invalid_choice"),
                                title="Info",
                                border_style="yellow",
                            )
                        )
                        continue
        else:
            # Fallback path without rich console; simple print loop
            while True:
                if _RICH_CONSOLE:
                    _RICH_CONSOLE.print(layout)
                choice = ask_text(translate("enter_choice"))
                if choice == "1":
                    manage_virtual_environment()
                    update_right(
                        Panel(
                            "Environment managed.", title="Status", border_style="green"
                        )
                    )
                elif choice == "2":
                    view_program_descriptions()
                    update_right(Panel("Descriptions viewed.", title="Programs"))
                elif choice == "3":

                    def set_content(renderable: Any) -> None:
                        update_right(renderable)

                    try:
                        run_processing_pipeline(content_updater=set_content)
                    except TypeError:
                        run_processing_pipeline()
                    update_right(
                        Panel(
                            _("pipeline_complete"),
                            title="Pipeline",
                            border_style="green",
                        )
                    )
                elif choice == "4":
                    view_logs()
                    update_right(Panel("Logs viewed.", title="Logs"))
                elif choice == "5":
                    reset_project()
                    update_right(
                        Panel(_("reset_complete"), title="Reset", border_style="green")
                    )
                elif choice.lower() == "q":
                    run_full_quality_suite()
                    update_right(
                        Panel(
                            translate("quality_suite_ok"),
                            title="Quality",
                            border_style="green",
                        )
                    )
                elif choice.lower() == "qq":
                    run_extreme_quality_suite()
                    update_right(
                        Panel(
                            translate("quality_suite_ok"),
                            title="Quality",
                            border_style="green",
                        )
                    )
                elif choice == "6":
                    rprint(translate("exiting"))
                    break
                else:
                    update_right(
                        Panel(
                            translate("invalid_choice"),
                            title="Info",
                            border_style="yellow",
                        )
                    )
                # loop continues
            # (Legacy dead code removed)
    finally:
        _TUI_MODE, _TUI_UPDATER = prev_mode, prev_updater


def main_menu() -> None:
    """Display the main menu using a Rich dashboard when available.

    Falls back to the plain text menu when Rich is not installed.

    Returns
    -------
    None
    """
    if ui_has_rich():
        _main_menu_rich_dashboard()
    else:
        _main_menu_plain()


def run_full_quality_suite() -> None:
    """Run the full local quality suite (mirrors CI gates).

    Runs a helper script that executes pre-commit checks, pytest with strict
    settings (warnings as errors, randomized order), docstring coverage gate,
    mutation testing, and Semgrep via the pre-commit push-stage hook.

    Returns
    -------
    None

    Examples
    --------
    >>> # Example invocation (non-interactive):  # doctest: +SKIP
    >>> run_full_quality_suite()  # doctest: +SKIP
    """
    python_executable = get_python_executable()
    helper = PROJECT_ROOT / "tools" / "run_all_checks.py"
    try:
        res = subprocess.run([python_executable, str(helper)], cwd=PROJECT_ROOT)
        if res.returncode == 0:
            ui_success(translate("quality_suite_ok"))
        else:
            ui_error(translate("quality_suite_fail"))
    except Exception as err:
        logger.error(f"Error running quality suite: {err}")


def run_extreme_quality_suite() -> None:
    """Run the EXTREME local quality suite (100 randomized pytest passes + mutation).

    This variant mirrors :func:`run_full_quality_suite` but uses an intensive mode
    that runs the tests with 100 different random seeds to stress order
    independence, then executes mutation testing, plus the same static analysis
    gates as the regular suite.

    Returns
    -------
    None

    Examples
    --------
    >>> # Example invocation (non-interactive):  # doctest: +SKIP
    >>> run_extreme_quality_suite()  # doctest: +SKIP
    """
    python_executable = get_python_executable()
    helper = PROJECT_ROOT / "tools" / "run_all_checks.py"
    try:
        res = subprocess.run(
            [python_executable, str(helper), "--extreme"], cwd=PROJECT_ROOT
        )
        if res.returncode == 0:
            ui_success(translate("quality_suite_ok"))
        else:
            ui_error(translate("quality_suite_fail"))
    except Exception as err:
        logger.error(f"Error running quality suite: {err}")


def parse_cli_args() -> argparse.Namespace:
    """Parse command-line arguments for the setup script.

    Returns
    -------
    argparse.Namespace
        Parsed arguments with options for language and venv control.
    """
    parser = argparse.ArgumentParser(
        description=(
            "School Data Processing Project Setup.\n"
            "When run interactively, you will be presented with a menu to either create a virtual environment or continue without one.\n"
            "Both choices are valid and supported. Use --no-venv to skip the menu and venv setup for automation."
        )
    )
    parser.add_argument(
        "--lang", type=str, choices=["en", "sv"], help="UI language (en or sv)"
    )
    parser.add_argument(
        "--no-venv",
        action="store_true",
        help="Skip virtual environment creation and dependency installation (bypasses the interactive menu)",
    )
    parser.add_argument(
        "--ui",
        type=str,
        choices=["rich", "textual"],
        default="rich",
        help="Select dashboard UI: 'rich' (default) or 'textual'",
    )
    return parser.parse_args()


def prompt_virtual_environment_choice() -> bool:
    """Prompt the user to choose between creating a venv or continuing without one.

    Returns
    -------
    bool
        ``True`` if the user chooses to create a virtual environment, otherwise ``False``.
    """
    ui_rule(translate("venv_menu_title"))
    ui_menu(
        [
            ("1", translate("venv_menu_option_1")[3:]),
            ("2", translate("venv_menu_option_2")[3:]),
        ]
    )
    while True:
        choice = ask_text(translate("venv_menu_prompt"))
        if choice == "1":
            return True
        if choice == "2":
            ui_info(translate("venv_skipped"))
            return False
        rprint(translate("invalid_choice"))  # pragma: no cover - trivial prompt loop


def parse_env_file(env_path: Path) -> dict[str, str]:
    """Parse a ``.env``-style file into a dictionary of environment variables.

    Parameters
    ----------
    env_path : Path
        Path to the ``.env`` file.

    Returns
    -------
    dict[str, str]
        Dictionary of environment variable keys and their values.
    """
    env_dict: dict[str, str] = {}
    if not env_path.exists():
        return env_dict
    with env_path.open("r", encoding="utf-8") as env_file:
        for line in env_file:
            match = ENV_KEY_VALUE_PATTERN.match(line)
            if match:
                key, value = match.groups()
                env_dict[key] = value
    return env_dict


def find_missing_env_keys(existing: dict[str, str], required: list[str]) -> list[str]:
    """Return required keys that are missing or empty in the existing ``.env`` dict.

    Parameters
    ----------
    existing : dict[str, str]
        Dictionary of current ``.env`` key-value pairs.
    required : list[str]
        List of required keys.

    Returns
    -------
    list[str]
        Missing or empty keys that must be provided.
    """
    return [key for key in required if not existing.get(key)]


def prompt_and_update_env(
    missing_keys: list[str], env_path: Path, existing: dict[str, str]
) -> None:
    """Prompt for missing Azure OpenAI values and update the ``.env`` file.

    Parameters
    ----------
    missing_keys : list[str]
        List of missing or empty keys.
    env_path : Path
        Path to the ``.env`` file.
    existing : dict[str, str]
        Dictionary of current ``.env`` key-value pairs to update in-place.

    Returns
    -------
    None
    """
    rprint(f"\n{_('azure_env_intro')}\n{_('azure_env_storage')}")
    for key in missing_keys:
        prompt = _("azure_env_prompt").format(key=key)
        value = ""
        while not value:
            value = ask_text(prompt)
        existing[key] = value

    # Write all required keys (preserve order), plus any other existing keys
    updated_lines = []
    for key in REQUIRED_AZURE_KEYS:
        updated_lines.append(f'{key}="{existing[key]}"\n')
    # Add any extra keys that were present in the original .env
    for key, value in existing.items():
        if key not in REQUIRED_AZURE_KEYS:
            updated_lines.append(f'{key}="{value}"\n')
    with env_path.open("w", encoding="utf-8") as env_file:
        env_file.writelines(updated_lines)
    logger.info(f"Updated {env_path} with Azure OpenAI values.")


def ensure_azure_openai_env() -> None:
    """Ensure that all required Azure OpenAI values exist in ``.env``.

    Prompts the user for any missing values and saves them.

    Returns
    -------
    None
    """
    # Use .env-example as the source of required keys (already in REQUIRED_AZURE_KEYS)
    env_dict = parse_env_file(ENV_PATH)
    missing_keys = find_missing_env_keys(env_dict, REQUIRED_AZURE_KEYS)
    if missing_keys:
        prompt_and_update_env(missing_keys, ENV_PATH, env_dict)
    else:
        logger.info(
            "All required Azure OpenAI values are present in .env."
        )  # pragma: no cover - info only


def run_ai_connectivity_check_interactive() -> bool:
    """Run a minimal AI connectivity test against the configured Azure endpoint.

    The test sends a strict instruction asking the model to only reply with
    ``"Status: OK"``. Any deviation or errors will be considered a failure and a
    helpful message will be printed for the user.

    Returns
    -------
    bool
        ``True`` if connectivity and response are OK; otherwise ``False``.
    """
    import asyncio
    import json

    import aiohttp

    # Build bilingual user prompt to yield an exact "Status: OK" reply
    user_prompt_en = (
        "This is a test. You must ONLY reply with the exact text 'Status: OK'. "
        "Are you ready? Reply 'Status: OK' if you are ready."
    )
    user_prompt_sv = (
        "Detta är ett test. Du måste ENDAST svara med exakt text 'Status: OK'. "
        "Är du redo? Svara 'Status: OK' om du är redo."
    )
    user_prompt = f"{user_prompt_sv}\n\n{user_prompt_en}"

    async def _check_once() -> tuple[bool, str]:
        try:
            # Lazy import to avoid heavy dependencies at import time
            from src.program2_ai_processor import OpenAIConfig

            cfg = OpenAIConfig()
            if not cfg.gpt4o_endpoint:
                return (
                    False,
                    "Missing OpenAI endpoint configuration.",
                )  # pragma: no cover - depends on external env
            headers: dict[str, str] = {
                "Content-Type": "application/json",
                "api-key": str(cfg.api_key),
            }
            payload = {
                "messages": [
                    {
                        "role": "system",
                        "content": "You are a concise assistant for connectivity tests.",
                    },
                    {"role": "user", "content": user_prompt},
                ],
                "max_tokens": 8,
                "temperature": 0.0,
            }
            async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=cfg.request_timeout)
            ) as session:
                async with session.post(
                    cfg.gpt4o_endpoint, json=payload, headers=headers
                ) as resp:
                    text = await resp.text()
                    if resp.status != 200:
                        return False, f"HTTP {resp.status}: {text[:200]}"
                    data = json.loads(text)
                    content = (
                        data.get("choices", [{}])[0]
                        .get("message", {})
                        .get("content", "")
                        .strip()
                    )
                    if content == "Status: OK":
                        return True, content
                    return False, f"Unexpected reply: {content[:200]}"
        except Exception as err:  # pragma: no cover - generic network failure
            return False, f"{type(err).__name__}: {err}"

    rprint(translate("ai_check_running"))
    ok, detail = asyncio.run(_check_once())
    if ok:
        rprint("[green]" + translate("ai_check_ok") + "[/green]")
        return True
    rprint("[red]" + translate("ai_check_fail") + "[/red]")
    rprint("[red]Details:[/red] " + detail)
    return False


def run_ai_connectivity_check_silent() -> tuple[bool, str]:
    """Run a minimal AI connectivity check and return status and details.

    This variant performs the same request as the interactive version but does not
    print to the console. It returns ``(ok, detail)`` where ``ok`` is ``True`` on
    success and ``detail`` contains a short text payload or error context.

    Returns
    -------
    tuple[bool, str]
        A tuple with success flag and a detail message.
    """
    import asyncio
    import json

    import aiohttp

    user_prompt_en = (
        "This is a test. You must ONLY reply with the exact text 'Status: OK'. "
        "Are you ready? Reply 'Status: OK' if you are ready."
    )
    user_prompt_sv = (
        "Detta är ett test. Du måste ENDAST svara med exakt text 'Status: OK'. "
        "Är du redo? Svara 'Status: OK' om du är redo."
    )
    user_prompt = f"{user_prompt_sv}\n\n{user_prompt_en}"

    async def _check_once() -> tuple[bool, str]:
        try:
            from src.program2_ai_processor import OpenAIConfig

            cfg = OpenAIConfig()
            if not cfg.gpt4o_endpoint:
                return False, "Missing OpenAI endpoint configuration."
            headers: dict[str, str] = {
                "Content-Type": "application/json",
                "api-key": str(cfg.api_key),
            }
            payload = {
                "messages": [
                    {
                        "role": "system",
                        "content": "You are a concise assistant for connectivity tests.",
                    },
                    {"role": "user", "content": user_prompt},
                ],
                "max_tokens": 8,
                "temperature": 0.0,
            }
            async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=cfg.request_timeout)
            ) as session:
                async with session.post(
                    cfg.gpt4o_endpoint, json=payload, headers=headers
                ) as resp:
                    text = await resp.text()
                    if resp.status != 200:
                        return False, f"HTTP {resp.status}: {text[:200]}"
                    data = json.loads(text)
                    content = (
                        data.get("choices", [{}])[0]
                        .get("message", {})
                        .get("content", "")
                        .strip()
                    )
                    if content == "Status: OK":
                        return True, content
                    return False, f"Unexpected reply: {content[:200]}"
        except Exception as err:
            return False, f"{type(err).__name__}: {err}"

    return asyncio.run(_check_once())


def entry_point() -> None:
    """Entry point that handles CLI, language selection, and main menu.

    Returns
    -------
    None
        Parses CLI args, configures language and environment, then opens menu.
    """
    args = parse_cli_args()
    global LANG
    if getattr(args, "lang", None):
        LANG = args.lang if args.lang in TEXTS else "en"

    # Textual dashboard mode if explicitly requested
    if getattr(args, "ui", "rich") == "textual":
        try:
            # Lazy import so that 'textual' isn't required for non-textual paths
            from src.ui_textual import DashboardContext, SetupDashboardApp

            ctx = DashboardContext(
                t=translate,
                get_program_descriptions=get_program_descriptions,
                run_ai_check=run_ai_connectivity_check_silent,
                run_program=run_program,
                render_pipeline_table=_render_pipeline_table,
                log_dir=LOG_DIR,
                program1_path=SRC_DIR / "program1_generate_markdowns.py",
                program2_path=SRC_DIR / "program2_ai_processor.py",
                program3_path=SRC_DIR / "program3_generate_website.py",
                set_tui_mode=set_tui_mode,
                lang=lambda: LANG,
                venv_dir=lambda: VENV_DIR,
            )
            app = SetupDashboardApp(ctx)
            app.run()
            sys.exit(0)
        except Exception as err:
            # Fallback to existing menu if textual is unavailable
            logger.warning(
                f"Textual UI unavailable or failed to start: {err}. Falling back to Rich UI."
            )

    # Bootstrap mode: if Rich & Questionary are unavailable and --no-venv is not set,
    # offer a minimal setup to create venv + install deps, then restart in the venv.
    def _should_bootstrap() -> bool:
        return (not ui_has_rich()) and (not _HAS_Q) and (not args.no_venv)

    if _should_bootstrap():  # pragma: no cover - environment dependent
        rprint(
            "Minimal bootstrap mode: setup virtual environment and install dependencies."
        )
        if ask_confirm(
            "Proceed to create venv and install from requirements.lock?",
            default_yes=True,
        ):
            manage_virtual_environment()
            # manage_virtual_environment() will execve into the venv on success.
            # If we are still here, exit gracefully.
            sys.exit(0)
        else:
            rprint(
                "Bootstrap aborted. You can run with --no-venv or install dependencies manually."
            )
            sys.exit(0)

    # Allow skipping the interactive language prompt on restarts after UI switch
    if not os.environ.get("SETUP_SKIP_LANGUAGE_PROMPT"):
        set_language()
    ui_header(translate("welcome"))
    if not args.no_venv:
        if not is_venv_active():  # pragma: no cover - interactive branch
            if (
                prompt_virtual_environment_choice()
            ):  # pragma: no cover - interactive branch
                manage_virtual_environment()  # pragma: no cover - interactive branch
    ensure_azure_openai_env()
    main_menu()
    sys.exit(0)


if __name__ == "__main__":  # pragma: no cover - direct script run
    entry_point()
