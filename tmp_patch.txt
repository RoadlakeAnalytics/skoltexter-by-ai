*** Begin Patch
*** Add File: tests/pipeline/ai_processor/test_ai_processor_client_unit.py
+"""Consolidated unit tests for src.src/pipeline/ai_processor/client.py
+
+This file was autogenerated by a repository consolidation script.
+Original test files:
+ - tests/pipeline/ai_processor/test_client_unit.py
+ - tests/pipeline/ai_processor/test_client_extra2_unit.py
+ - tests/pipeline/ai_processor/test_client_extra_unit.py
+ - tests/pipeline/ai_processor/test_client_more_unit.py
+"""
+
+
+import json
+import asyncio
+import aiohttp
+from types import SimpleNamespace
+import pytest
+from src.pipeline.ai_processor.client import AIAPIClient
+
+### BEGIN ORIGINAL: tests/pipeline/ai_processor/test_client_unit.py
+class DummyResponse:
+    def __init__(self, status: int, text_value: str):
+        self.status = status
+        self._text = text_value
+
+    async def text(self):
+        return self._text
+
+    async def __aenter__(self):
+        return self
+
+    async def __aexit__(self, exc_type, exc, tb):
+        return False
+
+
+class DummySession:
+    def __init__(self, resp: object | Exception):
+        self.resp = resp
+
+    def post(self, *a, **k):
+        if isinstance(self.resp, Exception):
+            raise self.resp
+        return self.resp
+
+
+@pytest.mark.asyncio
+async def test_no_endpoint_returns_config_error():
+    cfg = SimpleNamespace(api_key="k", gpt4o_endpoint="")
+    client = AIAPIClient(cfg)
+    ok, content, data = await client.process_content(None, {})
+    assert ok is False
+    assert content is None
+    assert data.get("error_type") == "ConfigurationError"
+
+
+@pytest.mark.asyncio
+async def test_http_200_invalid_json_returns_raw_text():
+    cfg = SimpleNamespace(api_key="k", gpt4o_endpoint="http://x", max_retries=0)
+    client = AIAPIClient(cfg)
+    resp = DummyResponse(200, "not-json")
+    session = DummySession(resp)
+    ok, content, data = await client.process_content(session, {"foo": "bar"})
+    assert ok is False
+    assert content is None
+    assert data.get("raw_response_text") == "not-json"
+
+
+@pytest.mark.asyncio
+async def test_http_200_with_fenced_content_is_cleaned():
+    cfg = SimpleNamespace(api_key="k", gpt4o_endpoint="http://x")
+    client = AIAPIClient(cfg)
+    payload = {"choices": [{"message": {"content": "```markdown\nHello\n```"}}]}
+    resp = DummyResponse(200, json.dumps(payload))
+    session = DummySession(resp)
+    ok, content, data = await client.process_content(session, {})
+    assert ok is True
+    assert content == "Hello"
+
+
+@pytest.mark.asyncio
+async def test_clienterror_returns_clienterror_type():
+    cfg = SimpleNamespace(api_key="k", gpt4o_endpoint="http://x", max_retries=0)
+    client = AIAPIClient(cfg)
+    session = DummySession(aiohttp.ClientError("boom"))
+    ok, content, data = await client.process_content(session, {})
+    assert ok is False
+    assert data.get("error_type") == "ClientError"
+### END ORIGINAL: tests/pipeline/ai_processor/test_client_unit.py
+### BEGIN ORIGINAL: tests/pipeline/ai_processor/test_client_extra2_unit.py
+class DummyResponse:
+    def __init__(self, status: int, text_value: str):
+        self.status = status
+        self._text = text_value
+
+    async def text(self) -> str:
+        return self._text
+
+    async def __aenter__(self):
+        return self
+
+    async def __aexit__(self, exc_type, exc, tb):
+        return False
+
+
+class DummySession:
+    def __init__(self, response: DummyResponse | Exception):
+        self.response = response
+
+    def post(self, *a, **k):
+        if isinstance(self.response, Exception):
+            raise self.response
+        return self.response
+
+
+@pytest.mark.asyncio
+async def test_missing_endpoint_returns_config_error() -> None:
+    """Return a configuration error tuple when endpoint is absent.
+
+    The client should not attempt any network activity when the endpoint
+    is not configured.
+    """
+    cfg = SimpleNamespace(gpt4o_endpoint="", api_key="x")
+    client = AIAPIClient(cfg)
+    ok, cleaned, raw = await client.process_content(None, {})
+    assert ok is False
+    assert cleaned is None
+    assert raw is not None and raw.get("error_type") == "ConfigurationError"
+
+
+@pytest.mark.asyncio
+async def test_json_decode_error_returns_raw_text() -> None:
+    """When the server returns invalid JSON, the raw text is exposed."""
+    cfg = SimpleNamespace(gpt4o_endpoint="http://x", api_key="k", max_retries=0)
+    session = DummySession(DummyResponse(200, "not-a-json"))
+    client = AIAPIClient(cfg)
+    ok, cleaned, raw = await client.process_content(session, {"a": 1})
+    assert ok is False
+    assert cleaned is None
+    assert raw == {"raw_response_text": "not-a-json"}
+
+
+@pytest.mark.asyncio
+async def test_success_with_fenced_code_strips_backticks() -> None:
+    """Content wrapped in fenced code blocks should be unwrapped."""
+    payload = {"choices": [{"message": {"content": "```py\nhello\n```"}}]}
+    cfg = SimpleNamespace(gpt4o_endpoint="http://x", api_key="k", max_retries=0)
+    session = DummySession(DummyResponse(200, json.dumps(payload)))
+    client = AIAPIClient(cfg)
+    ok, cleaned, raw = await client.process_content(session, {})
+    assert ok is True
+    assert cleaned == "hello"
+    assert isinstance(raw, dict) and "choices" in raw
+
+
+@pytest.mark.asyncio
+async def test_empty_choices_retries_and_returns_false(monkeypatch) -> None:
+    """Empty `choices` should cause retries and ultimately a False result."""
+    payload = {"choices": []}
+    cfg = SimpleNamespace(gpt4o_endpoint="http://x", api_key="k", max_retries=1, backoff_factor=0)
+    session = DummySession(DummyResponse(200, json.dumps(payload)))
+    client = AIAPIClient(cfg)
+
+    # Make sleeps no-ops to keep the test fast. Patch with an async
+    # no-op to avoid recursive calls to `asyncio.sleep` which would
+    # otherwise cause infinite recursion and blow up memory.
+    async def _noop_sleep(*_args, **_kwargs):
+        return None
+
+    monkeypatch.setattr(asyncio, "sleep", _noop_sleep)
+    ok, cleaned, raw = await client.process_content(session, {})
+    assert ok is False
+    assert cleaned is None
+    assert raw == payload
+
+
+@pytest.mark.asyncio
+async def test_clienterror_handling_returns_error_object() -> None:
+    """Network errors from aiohttp should be reported as ClientError."""
+    cfg = SimpleNamespace(gpt4o_endpoint="http://x", api_key="k", max_retries=0)
+    session = DummySession(aiohttp.ClientError("boom"))
+    client = AIAPIClient(cfg)
+    ok, cleaned, raw = await client.process_content(session, {})
+    assert ok is False
+    assert cleaned is None
+    assert raw is not None and raw.get("error_type") == "ClientError"
+### END ORIGINAL: tests/pipeline/ai_processor/test_client_extra2_unit.py
+### BEGIN ORIGINAL: tests/pipeline/ai_processor/test_client_extra_unit.py
+class SeqResponse:
+    def __init__(self, session):
+        self._session = session
+
+    async def __aenter__(self):
+        status, text = self._session.seq.pop(0)
+        self.status = status
+        self._text = text
+
+        async def textfn():
+            return self._text
+
+        self.text = textfn
+        return self
+
+    async def __aexit__(self, exc_type, exc, tb):
+        return False
+
+
+class SeqSession:
+    def __init__(self, seq):
+        # operate on a mutable list so SeqResponse instances consume it
+        self.seq = list(seq)
+
+    def post(self, *a, **k):
+        return SeqResponse(self)
+
+
+@pytest.mark.asyncio
+async def test_429_then_success_retry():
+    cfg = SimpleNamespace(api_key="k", gpt4o_endpoint="http://x", max_retries=1, backoff_factor=0, retry_sleep_on_429=0)
+    client = AIAPIClient(cfg)
+    # First response 429, then a successful 200 with valid content
+    good = {"choices": [{"message": {"content": "OK"}}]}
+    seq = [(429, "rate"), (200, json.dumps(good))]
+    session = SeqSession(seq)
+    ok, content, data = await client.process_content(session, {})
+    assert ok is True
+    assert content == "OK"
+
+
+@pytest.mark.asyncio
+async def test_choices_not_list_returns_data():
+    cfg = SimpleNamespace(api_key="k", gpt4o_endpoint="http://x", max_retries=0)
+    client = AIAPIClient(cfg)
+    payload = {"choices": "bad"}
+    session = SeqSession([(200, json.dumps(payload))])
+    ok, content, data = await client.process_content(session, {})
+    assert ok is False
+    assert isinstance(data, dict)
+### END ORIGINAL: tests/pipeline/ai_processor/test_client_extra_unit.py
+### BEGIN ORIGINAL: tests/pipeline/ai_processor/test_client_more_unit.py
+class Resp:
+    def __init__(self, status, text):
+        self.status = status
+        self._text = text
+
+    async def text(self):
+        return self._text
+
+    async def __aenter__(self):
+        return self
+
+    async def __aexit__(self, *a):
+        return False
+
+
+class Sess:
+    def __init__(self, resp):
+        self.resp = resp
+
+    def post(self, *a, **k):
+        return self.resp
+
+
+@pytest.mark.asyncio
+async def test_http_500_then_fail_no_retry():
+    cfg = SimpleNamespace(api_key="k", gpt4o_endpoint="http://x", max_retries=0, backoff_factor=0)
+    client = AIAPIClient(cfg)
+    payload = {}
+    session = Sess(Resp(500, "err body"))
+    ok, content, data = await client.process_content(session, payload)
+    assert ok is False
+    assert data.get("status_code") == 500 or data.get("error_body") == "err body"
+
+
+@pytest.mark.asyncio
+async def test_timeout_error_branch():
+    cfg = SimpleNamespace(api_key="k", gpt4o_endpoint="http://x", max_retries=0, backoff_factor=0)
+    client = AIAPIClient(cfg)
+
+    class BadSess:
+        def post(self, *a, **k):
+            raise TimeoutError()
+
+    ok, content, data = await client.process_content(BadSess(), {})
+    assert ok is False
+    assert data.get("error_type") in ("TimeoutError", "Exception")
+### END ORIGINAL: tests/pipeline/ai_processor/test_client_more_unit.py
*** Delete File: tests/pipeline/ai_processor/test_client_unit.py
*** Add File: tests/pipeline/markdown_generator/test_markdown_generator_runner_unit.py
+"""Consolidated unit tests for src.src/pipeline/markdown_generator/runner.py
+
+This file was autogenerated by a repository consolidation script.
+Original test files:
+ - tests/pipeline/markdown_generator/test_runner_unit.py
+ - tests/program1/test_cli.py
+"""
+
+
+import logging
+from types import SimpleNamespace
+from src.pipeline.markdown_generator import runner
+import src.pipeline.markdown_generator.runner as p1
+
+### BEGIN ORIGINAL: tests/pipeline/markdown_generator/test_runner_unit.py
+def test_configure_logging_swallow(monkeypatch, tmp_path):
+    # Make FileHandler raise to ensure configure_logging swallows it
+    monkeypatch.setattr(logging, "FileHandler", lambda *a, **k: (_ for _ in ()).throw(RuntimeError("boom")))
+    runner.configure_logging(enable_file=True)
+
+
+def test_run_from_config_success(monkeypatch):
+    monkeypatch.setattr(runner, "load_template_and_placeholders", lambda p: ("tpl", {}))
+    monkeypatch.setattr(runner, "process_csv_and_generate_markdowns", lambda c, t, ph, out: 3)
+    ok = runner.run_from_config(csv_path=__import__('pathlib').Path('.'), template_path=__import__('pathlib').Path('.'), output_dir=__import__('pathlib').Path('.'))
+    assert ok is True
+
+
+def test_run_from_config_failure(monkeypatch):
+    monkeypatch.setattr(runner, "load_template_and_placeholders", lambda p: (_ for _ in ()).throw(RuntimeError("bad")))
+    ok = runner.run_from_config()
+    assert ok is False
+### END ORIGINAL: tests/pipeline/markdown_generator/test_runner_unit.py
+### BEGIN ORIGINAL: tests/program1/test_cli.py
+def test_configure_logging_filehandler_error(monkeypatch):
+    """Test Configure logging filehandler error."""
+
+    class BadFH:
+        """Test BadFH."""
+
+        def __init__(self, *a, **k):
+            """Test Init."""
+            raise RuntimeError("fh error")
+
+    monkeypatch.setattr(p1.logging, "FileHandler", BadFH)
+    p1.configure_logging("INFO", enable_file=True)
+### END ORIGINAL: tests/program1/test_cli.py
*** Delete File: tests/pipeline/markdown_generator/test_runner_unit.py
*** Add File: tests/pipeline/website_generator/test_website_generator_runner_unit.py
+"""Consolidated unit tests for src.src/pipeline/website_generator/runner.py
+
+This file was autogenerated by a repository consolidation script.
+Original test files:
+ - tests/pipeline/website_generator/test_runner_extra_unit.py
+ - tests/pipeline/website_generator/test_runner_web_unit.py
+"""
+
+
+from types import SimpleNamespace
+from pathlib import Path
+import src.pipeline.website_generator.runner as runner
+from src.pipeline.website_generator import runner
+
+### BEGIN ORIGINAL: tests/pipeline/website_generator/test_runner_extra_unit.py
+def test_run_from_config_writes_no_data(monkeypatch, tmp_path: Path):
+    """If loader returns empty list a 'no data' page is written."""
+    monkeypatch.setattr(runner, "load_school_data", lambda csv, md: [])
+    called = {}
+
+    def fake_write(html, out):
+        called["ok"] = True
+
+    monkeypatch.setattr(runner, "write_html_output", fake_write)
+    ok = runner.run_from_config(csv_path=tmp_path / "s.csv", ai_markdown_dir=tmp_path, output_file=tmp_path / "out.html")
+    assert ok is True and called.get("ok")
+
+
+def test_run_from_config_loader_exception_returns_false(monkeypatch, tmp_path: Path):
+    """Loader exceptions should be caught and reported as False."""
+    def bad_loader(*a, **k):
+        raise RuntimeError("boom")
+
+    monkeypatch.setattr(runner, "load_school_data", bad_loader)
+    ok = runner.run_from_config(csv_path=tmp_path / "s.csv", ai_markdown_dir=tmp_path, output_file=tmp_path / "out.html")
+    assert ok is False
+### END ORIGINAL: tests/pipeline/website_generator/test_runner_extra_unit.py
+### BEGIN ORIGINAL: tests/pipeline/website_generator/test_runner_web_unit.py
+def test_run_from_config_no_data(monkeypatch, tmp_path: Path):
+    out = tmp_path / "out.html"
+    monkeypatch.setattr(runner, "load_school_data", lambda csv, md: [])
+    monkeypatch.setattr(runner, "write_html_output", lambda html, path: path.write_text(html))
+    ok = runner.run_from_config(csv_path=tmp_path / "no.csv", ai_markdown_dir=tmp_path, output_file=out)
+    assert ok is True
+    assert out.exists()
+
+
+def test_run_from_config_with_data(monkeypatch, tmp_path: Path):
+    out = tmp_path / "out2.html"
+    monkeypatch.setattr(runner, "load_school_data", lambda csv, md: [{"a": 1}])
+    monkeypatch.setattr(runner, "generate_final_html", lambda schools, tpl: "<html>ok</html>")
+    monkeypatch.setattr(runner, "write_html_output", lambda html, path: path.write_text(html))
+    ok = runner.run_from_config(csv_path=tmp_path / "ok.csv", ai_markdown_dir=tmp_path, output_file=out)
+    assert ok is True
+    assert out.read_text() == "<html>ok</html>"
+### END ORIGINAL: tests/pipeline/website_generator/test_runner_web_unit.py
+
*** Delete File: tests/pipeline/website_generator/test_runner_web_unit.py
*** Add File: tests/setup/ui/test_ui_layout_unit.py
+"""Tests for the lightweight layout helpers. (unique name)"""
+
+from src.setup.ui.layout import _Slot, build_dashboard_layout
+
+
+def test_slot_update():
+    s = _Slot("init")
+    assert s.value == "init"
+    s.update("next")
+    assert s.value == "next"
+
+
+def test_build_dashboard_layout_old_and_new_signatures():
+    def tr(x):
+        return x
+
+    layout_old = build_dashboard_layout(tr, "welcome", None, "en")
+    assert "header" in layout_old
+    assert layout_old["header"].value == "welcome"
+
+    layout_new = build_dashboard_layout("welcome2")
+    assert layout_new["header"].value == "welcome2"
+
*** Delete File: tests/setup/ui/test_layout_unit.py
*** Add File: tests/setup/ui/test_ui_programs_unit.py
+"""Consolidated unit tests for src.src/setup/ui/programs.py
+
+This file was autogenerated by a repository consolidation script.
+Original test files:
+ - tests/setup/ui/test_programs_unit.py
+ - tests/setup/ui/test_programs_extra_unit.py
+ - tests/setup/ui/test_programs_more_unit.py
+"""
+
+
+from pathlib import Path
+import tempfile
+from src.setup.ui import programs
+from types import SimpleNamespace
+import src.setup.ui.programs as prog
+
+### BEGIN ORIGINAL: tests/setup/ui/test_programs_unit.py
+def test_get_program_descriptions_has_three():
+    desc = programs.get_program_descriptions()
+    assert set(desc.keys()) == {"1", "2", "3"}
+
+
+def test_view_program_descriptions_plain(monkeypatch):
+    # Simulate choosing program 1 then returning
+    seq = ["1", "0"]
+    monkeypatch.setattr(programs, "ask_text", lambda prompt: seq.pop(0))
+    monkeypatch.setattr(programs, "ui_menu", lambda items: None)
+    monkeypatch.setattr(programs, "ui_rule", lambda arg: None)
+    monkeypatch.setattr(programs, "ui_has_rich", lambda: False)
+    programs.view_program_descriptions()
+
+
+def test__view_program_descriptions_tui(monkeypatch):
+    captured = {}
+
+    def update_right(obj):
+        captured["last"] = obj
+
+    monkeypatch.setattr(programs, "ask_text", lambda prompt: "1")
+    programs._view_program_descriptions_tui(update_right, lambda p: None)
+    assert "last" in captured
+
+
+def test__view_logs_tui_no_logs(monkeypatch, tmp_path: Path):
+    monkeypatch.setattr(programs, "LOG_DIR", tmp_path)
+    captured = {}
+
+    def update_right(obj):
+        captured["last"] = obj
+
+    programs._view_logs_tui(update_right, lambda p: None)
+    assert "last" in captured
+
+
+def test_view_logs_with_files(monkeypatch, tmp_path: Path):
+    monkeypatch.setattr(programs, "LOG_DIR", tmp_path)
+    f = tmp_path / "a.log"
+    f.write_text("hello")
+    seq = ["1", "0"]
+    monkeypatch.setattr(programs, "ask_text", lambda prompt: seq.pop(0))
+    monkeypatch.setattr(programs, "ui_menu", lambda items: None)
+    monkeypatch.setattr(programs, "ui_rule", lambda arg: None)
+    monkeypatch.setattr(programs, "ui_has_rich", lambda: False)
+
+    programs.view_logs()
+### END ORIGINAL: tests/setup/ui/test_programs_unit.py
+### BEGIN ORIGINAL: tests/setup/ui/test_programs_extra_unit.py
+def test_get_program_descriptions_uses_translate(monkeypatch):
+    """Descriptions are looked up via the translate function."""
+    def fake_translate(key: str) -> str:
+        return f"{key}_val"
+
+    monkeypatch.setattr(prog, "translate", fake_translate)
+    desc = prog.get_program_descriptions()
+    assert "1" in desc and isinstance(desc["1"], tuple)
+
+
+def test_view_program_descriptions_plain(monkeypatch):
+    """When non-rich, program descriptions are printed as plain text."""
+    monkeypatch.setattr(prog, "ui_rule", lambda *a, **k: None)
+    monkeypatch.setattr(prog, "ui_menu", lambda *a, **k: None)
+    monkeypatch.setattr(prog, "get_program_descriptions", lambda: {"1": ("S", "L")})
+    answers = ["1", "0"]
+    printed = []
+    monkeypatch.setattr(prog, "ask_text", lambda prompt: answers.pop(0))
+    monkeypatch.setattr(prog, "rprint", lambda *a, **k: printed.append(a))
+    monkeypatch.setattr(prog, "ui_has_rich", lambda: False)
+
+    prog.view_program_descriptions()
+    assert any("L" in str(p) for p in printed)
+
+
+def test_view_logs_no_logs_prints(monkeypatch, tmp_path: Path):
+    """When there are no log files the user is informed via rprint."""
+    monkeypatch.setattr(prog, "ui_rule", lambda *a, **k: None)
+    monkeypatch.setattr(prog, "rprint", lambda *a, **k: (_ for _ in ()).throw(AssertionError("rprint called")))
+    # Point LOG_DIR to an empty temporary directory
+    monkeypatch.setattr(prog, "LOG_DIR", tmp_path)
+
+    # view_logs should return early without raising if rprint is called
+    try:
+        prog.view_logs()
+    except AssertionError:
+        # rprint should have been invoked signalling no logs
+        pass
+### END ORIGINAL: tests/setup/ui/test_programs_extra_unit.py
+### BEGIN ORIGINAL: tests/setup/ui/test_programs_more_unit.py
+def test_view_program_descriptions_invalid_then_exit(monkeypatch):
+    seq = ["9", "0"]
+    monkeypatch.setattr(programs, "ask_text", lambda prompt: seq.pop(0))
+    monkeypatch.setattr(programs, "ui_menu", lambda items: None)
+    monkeypatch.setattr(programs, "ui_rule", lambda arg: None)
+    monkeypatch.setattr(programs, "ui_has_rich", lambda: False)
+    programs.view_program_descriptions()
+
+
+def test__view_logs_tui_select_by_name(monkeypatch, tmp_path: Path):
+    # Prepare log files
+    d = tmp_path
+    (d / "alpha.log").write_text("one")
+    (d / "beta.log").write_text("two")
+    monkeypatch.setattr(programs, "LOG_DIR", d)
+    # First call selects by literal name, then 0 to exit
+    seq = ["alpha.log", "0"]
+    monkeypatch.setattr(programs, "ask_text", lambda prompt: seq.pop(0))
+
+    captured = {}
+
+    def update_right(obj):
+        captured.setdefault("last", obj)
+
+    programs._view_logs_tui(update_right, lambda p: None)
+    assert "last" in captured
+### END ORIGINAL: tests/setup/ui/test_programs_more_unit.py
*** Delete File: tests/setup/ui/test_programs_unit.py
*** End Patch